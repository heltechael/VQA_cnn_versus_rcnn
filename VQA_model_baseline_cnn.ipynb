{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkXb-uJAdeKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd0afeb-bc5d-4d09-9195-b5093627e424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch '/content/drive/MyDrive/Deep_learning/epoch_statistics_baseline.csv'"
      ],
      "metadata": {
        "id": "ds1I7SC5C_cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/drive/MyDrive/Deep_learning/model_states'\n",
        "!mkdir '/content/drive/MyDrive/Deep_learning/data'"
      ],
      "metadata": {
        "id": "BAGvX7hIDDin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06dfa328-e53d-43eb-b0b7-7b25ea9fce5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Deep_learning/model_states’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Deep_learning/data.zip'"
      ],
      "metadata": {
        "id": "x_DuWtUETSAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "mm1mex8qrB2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "tJNiMFFaq5FG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d244c3f-cb0f-4734-bbb3-d171a74aa80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset and Dataloaders"
      ],
      "metadata": {
        "id": "lHPmHY0ArDrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "SUvOiwH1rHIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training questions and annotations\n",
        "with open(\"data/v2_OpenEnded_mscoco_train2014_questions.json\", \"r\") as file:\n",
        "    train_questions_json = json.load(file)\n",
        "    train_questions = [item[\"question\"] for item in train_questions_json[\"questions\"]]\n",
        "\n",
        "with open(\"data/v2_mscoco_train2014_annotations.json\", \"r\") as file:\n",
        "    train_annotations_json = json.load(file)\n",
        "    train_answers = [\n",
        "        item[\"multiple_choice_answer\"] for item in train_annotations_json[\"annotations\"]\n",
        "    ]\n",
        "\n",
        "# Image paths for training\n",
        "train_image_dir = \"data/train2014/\"\n",
        "train_images = [\n",
        "    os.path.join(train_image_dir, \"COCO_train2014_{:012d}.jpg\".format(item[\"image_id\"]))\n",
        "    for item in train_annotations_json[\"annotations\"]\n",
        "]\n",
        "\n",
        "# Load validation questions and annotations\n",
        "with open(\"data/v2_OpenEnded_mscoco_val2014_questions.json\", \"r\") as file:\n",
        "    val_questions_json = json.load(file)\n",
        "    val_questions = [item[\"question\"] for item in val_questions_json[\"questions\"]]\n",
        "\n",
        "with open(\"data/v2_mscoco_val2014_annotations.json\", \"r\") as file:\n",
        "    val_annotations_json = json.load(file)\n",
        "    val_answers = [\n",
        "        item[\"multiple_choice_answer\"] for item in val_annotations_json[\"annotations\"]\n",
        "    ]\n",
        "\n",
        "# Image paths for validation\n",
        "val_image_dir = \"data/val2014/\"\n",
        "val_images = [\n",
        "    os.path.join(val_image_dir, \"COCO_val2014_{:012d}.jpg\".format(item[\"image_id\"]))\n",
        "    for item in val_annotations_json[\"annotations\"]\n",
        "]"
      ],
      "metadata": {
        "id": "K01oHE7nrGfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare images, questions, answers, and tokenizer"
      ],
      "metadata": {
        "id": "w56Q1NI5rSyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE_TRAIN = 15000\n",
        "train_indices = random.sample(range(len(train_images)), SAMPLE_SIZE_TRAIN)\n",
        "#train_indices = list(range(0, SAMPLE_SIZE_TRAIN-1))\n",
        "train_selected_images = [train_images[i] for i in train_indices]\n",
        "train_selected_questions = [train_questions[i] for i in train_indices]\n",
        "train_selected_answers = [train_answers[i] for i in train_indices]\n",
        "\n",
        "# Select a subset for validation\n",
        "SAMPLE_SIZE_VAL = 3000\n",
        "eval_indices = random.sample(range(len(val_images)), SAMPLE_SIZE_VAL*2)\n",
        "val_indices = eval_indices[:len(eval_indices)//2]\n",
        "test_indices = eval_indices[len(eval_indices)//2:]\n",
        "\n",
        "val_selected_images = [val_images[i] for i in val_indices]\n",
        "val_selected_questions = [val_questions[i] for i in val_indices]\n",
        "val_selected_answers = [val_answers[i] for i in val_indices]\n",
        "\n",
        "test_selected_images = [val_images[i] for i in test_indices]\n",
        "test_selected_questions = [val_questions[i] for i in test_indices]\n",
        "test_selected_answers = [val_answers[i] for i in test_indices]\n",
        "\n",
        "# Find training classes\n",
        "train_classes = set(train_selected_answers)\n",
        "print(f\"Training classes: {train_classes}\")\n",
        "print(f\"Number of training classes: {len(train_classes)}\")\n",
        "\n",
        "# Filter validation answers to include only those present in the training set\n",
        "val_filtered_indices = [i for i, answer in enumerate(val_selected_answers) if answer in train_classes]\n",
        "test_filtered_indices = [i for i, answer in enumerate(test_selected_answers) if answer in train_classes]\n",
        "\n",
        "print(f'Number of validation samples: {len(val_filtered_indices)}')\n",
        "print(f'Number of test samples: {len(test_filtered_indices)}')\n",
        "\n",
        "val_filtered_images = [val_selected_images[i] for i in val_filtered_indices]\n",
        "val_filtered_questions = [val_selected_questions[i] for i in val_filtered_indices]\n",
        "val_filtered_answers = [val_selected_answers[i] for i in val_filtered_indices]\n",
        "\n",
        "test_filtered_images = [test_selected_images[i] for i in test_filtered_indices]\n",
        "test_filtered_questions = [test_selected_questions[i] for i in test_filtered_indices]\n",
        "test_filtered_answers = [test_selected_answers[i] for i in test_filtered_indices]\n",
        "\n",
        "# Merge training and validation questions\n",
        "combined_questions = train_selected_questions + val_filtered_questions + test_filtered_questions\n",
        "\n",
        "# Fit tokenizer on the combined set of questions\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(combined_questions)\n",
        "tokenized_combined_questions = tokenizer.texts_to_sequences(combined_questions)\n",
        "max_question_length = max(len(seq) for seq in tokenized_combined_questions)\n",
        "\n",
        "# Tokenize and pad training questions\n",
        "train_tokenized_questions = tokenizer.texts_to_sequences(train_selected_questions)\n",
        "train_padded_questions = pad_sequences(train_tokenized_questions, maxlen=max_question_length)\n",
        "\n",
        "# Tokenize and pad validation questions\n",
        "val_tokenized_questions = tokenizer.texts_to_sequences(val_filtered_questions)\n",
        "val_padded_questions = pad_sequences(val_tokenized_questions, maxlen=max_question_length)\n",
        "\n",
        "# Tokenize and pad validation questions\n",
        "test_tokenized_questions = tokenizer.texts_to_sequences(test_filtered_questions)\n",
        "test_padded_questions = pad_sequences(test_tokenized_questions, maxlen=max_question_length)\n",
        "\n",
        "# Convert answers to classes\n",
        "label_encoder = LabelEncoder()\n",
        "train_answer_classes = label_encoder.fit_transform(train_selected_answers)\n",
        "\n",
        "# Convert filtered eval answers to classes using label encoder\n",
        "val_answer_classes = label_encoder.transform(val_filtered_answers)\n",
        "test_answer_classes = label_encoder.transform(test_filtered_answers)"
      ],
      "metadata": {
        "id": "BwFX32SnrV3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03959095-fa6a-43c4-b7eb-afb4a726e5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classes: {'lego', 'on building', 'detroit', 'energy', 'snowboarding', 'gaming', 'fall', 'painting', 'krispy kreme', 'saint', 'ring', 'mark ski trail', 'high five', 'in milk', 'ramp', 'dinner', 'tabby', 'lunch', 'boeing', 'westjet', 'playing wii', 'cookies', 'eating', 'hotel', 'out of service', 'red pink and white', 'aurora', 'no piano', 'moving', 'warm', 'nowhere', 'plastic', 'above stop sign', '2 bags', 'brothers', 'bill clinton', 'orange juice', 'corner', 'bicycle', 'spring', '9:15', 'pillows', 'several', 'bottle', 'public', 'mario kart', 'orange and black', 'ham, peppers, cheese, sauce, dough', 'down street', 'messy', 'asus', 'pc', 'ankle strap', 'papers', 'hard drive', 'racket', 'male and female', 'surfer', 'used', 'portable', 'hot dogs', 'in front', 'ave', 'parking meter', 'there not reptiles', 'shades', 'mums', 'crossed', 'north america', 'president', 'dusk', 'red and blue', 'on pole', 'bow tie', 'not steep', 'road', 'necessity', 'child', 'aquafresh', 'pear', \"mcdonald's\", 'wetsuit', 'news1130', 'toothpick', 'smiling', 'through tunnel', 'store', 'shoes', 'oscar meyer', 'engines', 'chimney', 'prom', '6 inches', 'wires', 'what and brown', 'photograph', 'parking lot', 'laying', 'microsoft word', 'library', 'tile', 'daytime', 'going to church', 'budweiser', 'stripe', 'madame tussauds', 'zac efron', 'licking her cub', 'age', 'bx59chf', 'space', 'plate', 'pepperoni', 'crash', 'hood', 'pennsylvania ave', 'in cabinet', 'ground', 'pacific', 'pictures', 'raising hands', 'cargo', 'chef', 'because it was built long time ago', '55', 'kickstand', 'golden gate bridge', 'ants', 'motorcycles', 'branch', 'box', 'puppy', 'skirt', 'locomotive', 'beach', 'windsurfing', 'diced', 'cat in hat', 'above toilet', 'blue and black', 'rough', '5383', 'red and silver', 'license', 'on floor', 'miles', 'houseplant', \"50's\", 'wagon', 'butter', \"luke blacks '11\", 'raspberries', 'winter', '1.5', 'poles', 'gold and black', 'plain', 'bosch', 'rua sem saida', 'scrambled', 'red shirt and hat', 'doughnut and coffee', 'behind plate', 'hijab', '10:05', 'departing', '135', 'mac', 'children', 'usaf', 'movie poster', 'above stove', 'to see', 'transportation', 'school buses', '60016', \"cesar's way\", 'focused on bird', 'strawberries', 'studying', 'whirlpool', 'pencils', 'socks', '32588', 'america', 'down', 'table', '15 minutes', 'mountain', 'small', 'general', 'wine glasses', 'on its legs', 'twin', 'in wagon', 'bus stop', 'dutchsimba', 'open', 'boston terrier', 'dodgers', 'will travel for vegan food', 'carnation', 'yellow and black', 'dishes', 'washing machine', '1 gallon', 'chopped', 'beer', 'pancake', 'on nightstand', 'off', 'bolster', 'carrot', 'turning', 'bus eireann', 'no water', 'on desk', 'juice', 'on toilet', 'lifeguards', 'sheffield', 'tv', 'apron', 'olives', 'daisy', 'jet skiing', 'swoosh', 'traffic light', 'photographer', 'avon', 'city', 'in air', 'westin', 'burlington northern', 'cutting pie', 'pole', 'power line', 'preacher', 'please do not climb up teddy bear', 'for soap', 'bunk', 'slayer', 'water', 'it is trained', 'construction', 'back left', 'menu', 'meadowview', 'water skiing', 'plant', \"l'oreal\", 'masonic', 'on tree', 'lettuce', 'head', 'toy', 'stainless', 'kimono', 'oxidation', 'cleaning products', 'pizza box', 'santa hat', 'baseball game', 'one in front', 'asparagus', 'tongue', 'flathead', 'chair', 'equal', 'pizza', 'elephants', 'very', 'limo', 'vietnamese', 'chickpeas', 'ahead', 'cans', 'mercedes-benz', 'glass', 'doll', 'coaster', 'straight ahead', 'bottom', 'sleeping', 'fork', 'plane', 'st andrews', 'seats', 'white and red', 'logo', 'time', 'hermiston', 'collar', 'flatbread', 'cotton', 'dog', 'candy canes', 'banana, kiwi, oranges, apple', 'stretching', 'oil', 'i', 'brushing teeth', 'garbage', 'on', '22000', 'urinal', 'sylantro', 'candle', 'maryland', 'baseball field', 'gray', 'ski resort', 'computer repair', '1 hour', 'bird seed', 'skateboarding', 'on street', 'flares', 'easter', 'snowy', '20 feet', 'citizen', 'westminster', 'trunk', 'relish', 'england', 'baskets', 'all', '656', 'shrimp', 'outward', 'iced tea', 'engine', '11.98 kg', 'cake', 'floral', 'goalie', 'pasture', 'hammer time', 'toast and muffin', 'nixon', 'on vernon blvd', 'skydiving', 'airport', 'bleachers', 'octopus', 'game show', 'grapes', 'legs', 'they are standing', 'light', 'linkinparkdude90', 'many colors', 'mooing', 'pink, yellow , purple, green and blue', '9:07', 'afternoon', 'behind laptop', 'sparrow', 'theophysile 218', 'making pizza', 'fedora', 'black and blue', 'flashlight', 'magnets', 'catcher', 'game', 'surfing', 'leather', 'ski poles', 'white, blue', 'fort', 'aquafina', 'windows', 'neighborhood', 'ball', '350', 'tray', 'di ponte s angelo', 'rhode island', '35', 'mushroom', 'yellow and green', 'riding wave', 'teddy bear', 'black, white, tan', 'flower', 'wii controller', 'toaster', 'herd', 'hay', 'fifth avenue', 'it was just cleaned', 'volkswagen', 'mustard and ketchup', 'stones', 'party', 'casino rama', 'asian', 'no parking', 'grass', 'grapefruit', 'lights are off', 'dad', 'oreos', 'horns', 'not very', 'neither', 'sold', '10', '2:05', 'mittens', 'on sign', 'monday', 'stethoscope', 'triangle', 'fields', 'pico', 'owl', 'no ramp', 'w', 'on her back', 'poor', '11:25', 'bush', 'federal express', 'playing game', '922', 'gala', '96', 'polar', 'soda', 'cell phones', 'school', 'qantas', '7:40', 'about to land', 'cutting hair', 'knives', 'jockey', 'running', 'surf', 'granite', 'behind cat', 'black one', 'dishwasher', 'seafood', 'no bear', 'walking', 'clock', 'jackie', '1163 011 b', 'skull', 'holding it', 'preparing', 'almas shriners', 'limes', 'raw', 'asia', 'butterfly', 'film strip', 'on left', '300', 'toothbrush and toothpaste', 'paper', 'cowboy', 'patience', 'tire', 'beans', 'railing', 'index', '1335', '12:40', 'downtown', '2363', 'oregon', 'hardwood', 'tortillas', 'ascending', 'on table', '11:35', 'kiwi', \"it's not\", 'indios verdes', '1:00', 'cherry', 'lake', '1920', 'tongs', '12:55', 'murky', '6861', 'seagull', 'dole', 'feline', 'old', 'haas', '9:05', 'accord', 'looking down', 'basketball', 'bananas', 'controller', 'sprite', 'green shirt', 'revenge', 'wheat', '30', 'tennis ball', 'yellow, black', 'sitting on branch', 'p', \"gravy's\", '13', 'fan', 'c7', 'going', 'no snow', 'jesus', 'dirt', 'people', 'taking off', 'carnival', 'side of road', 'yellow, blue, red, black', '540', '1:50', 'pigeon', 'octagon', 'striped', 'dairy queen', \"they don't\", 'ski boots', 'near base', 'thomas tank engine', 'vases', 'exit', 'beard', 'panda', 'chest', 'fire extinguisher', 'london', 'stove', 'the lab', 'no stopping', 'very tall', 'grape', 'washing dishes', 'hester', 'wood and glass', 'classroom', 'banana split', 'buildings', 'ladder', 'bakery', '19/03/2009', 'smart car', 'signing autographs', '5:35', 'horse', 'rugby', 'dots', 'field', 'crossing', 'florida', 'ears', 'woman in back', 'sunlight', 'donuts', 'dawn or dusk', 'farm', 'frog', 'evening', 'rectangle', 'soup', 'june 17 2012', 'no one', 'hit ball', 'grill', '44', 'shadow', 'on man', 'drawer', '4th street', 'parasails', 'steak potatoes and carrots', 'lamp', 'too hot', 'windy', 'wood grain', 'in water', 'breakfast', 'barber shop', 'ceramic', 'brown and white', 'chain link', 'samuel', 'playing tennis', 'deer', 'quiet', 'birthday', 'taqueria lety', 'madison concourse hotel', 'outside', 'young', 'wool', 'burner', 'make coffee', 'boogie board', 'hide', 'peephole view', 'apple', 'vegetables', 'basil', '66', 'arrow', 'cardinals', 'dell', 'foot', 'swimming trunks', 'television', 'ceremony', 'couple', 'running beside horse', 'in front of woman', 'behind building', 'coffee cake', 'handkerchief', 'randomly', 'day today', 'giants', 'smooth', 'throw ball', 'halved', 'table leg', 'i love my geek', 'cane', 'under him', 'cigarettes', 'ducati', 'formal', 'wood', 'virgin', 'police', 'juicer', 'owls', 'applying makeup', 'salad', 'orange and white', 'tired', 'batter', 'chewing', 'cabs', 'rice', '2013', 'corporate', 'g', 'awake', 'resting', 'leaning', '32', 'rectangles', 'on water', 'blowing out candles', 'frame', 'cub following bear', 'only bus', 'checkered', 'trinkets', 'footprints', 'noon', 'santa fe', 'oven', 'e stephenson', 'wine tasting', 'rainy', 'diversion', '1589', 'heart', 'heels', 'pizza hut', 'social media', '395', 'sectional', 'tablet', 'sitting', 'eagle', 'germany', 'lettuce, tomato', '50', 'hula hoop', 'bear', 'miller', \"man's back\", 'cottage', 'santa', 'floss', 'carnival ride', 'green and black', 'skiers', 'whole', 'daf', 'blue, white, red, yellow', 'tracks', 'peppers', 'to sit on', 'large', 'prohibited', 'jam', 'candy', 'lays', 'lamb', 'on chair', '36', 'zoo', 'stripes', 'entrance', 'top bunk', 'mattress', '100 ft', '1058', 'riding horse', 'google', 'waiting for bus', 'roadblock', 'on bench', 'ponytail', 'cell phone', 'english national opera', 'men', 'commercial', 'bag', 'electronics', 'sierra mist', 'air canada', 'barber vintage', 'photography', 'convoy', '163-000-5', 'makeup', 'red, white and blue', 'banana and orange', 'finch', 'hair', 'tall', '2:57 pm', 'feathers', 'to dry hair', 'lily pads', 'dining room', 'costume', 'boots', 'sausages', 'crane', 'nighttime', 'tape', 'winnie pooh', 'coffee', 'canary', 'boat', 'ostersund', 'shirt', 'playing baseball', 'hairnet', 'tree', 'pillow', 'vietnam', 'zj', 'vaxi', 'above', 'appetizers', 'friedkin', 'bigger one', 'best buy', '6:08', 'cemetery', 'german shepherd', 'kites', 'river', 'popcorn', 'milwaukee', \"smucker's\", '3:13', 'burton', 'warming up', 'porch', 'over easy', 'hot dog', '11', 'mountainous', 'book', 'grass and trees', 'hot dog and fries', 'cap', 'any of them', 'grandma', 'in basket', 'man', 'boats', 'nitro', 'plaza drive', 'tower', '6', 'entering', '2:10', 'living', 'pastries', 'any', 'eating animals', 'laptop', 'decoration', 'souffle', 'squares', 'disc golf', 'knee high', 'colander', 'bus route', '2400', 'scenery', 'landing', 'upper', 'bat', 'japan', 'bicycles', 'soccer ball', 'pedestrians', 'reading', 'bird', 'baked', 'partying', 'reichenberger strasse', 'buoy', 'talking', 'low', '2 men', '0.99', 'robe', 'good', 'burnt', 'great western', 'foil', 'air conditioner', 'friends', 'on body', 'dough', 'skateboard', 'cedar st', 'reins', 'calico', 'night', 'daytona', 'vent', 'comfort', 'books', '6:45', 'peas', 'on train', 'out', 'batteries', 'far', 'twisted', 'newspaper', 'jumping', 'palm', 'doorknob', 'orange', 'hers', 'organic', 'handle', 'house', 'clear', 'pepsi', 'laying down', 'plywood', 'wii remote', '5:23', 'bobcat goldthwait', 'mut', 'arugula', 'rossignol', 'steering wheel', 'onions', 'park', 'metal', 'tie', 'barriers', 'rawlings', 'to', 'delivered', 'chocolate', 'from below', 'pulp fiction', 'germanwings', 'keep giraffes in', \"it's raining\", 'window', 'houses', 'salmon and broccoli', 'falling', 'private', 'jal', 'tennis match', 'cutting', 'tulips', 'cart', 'alex', 'in focus', '1:03', 'great', 'urban', 'woods', 'pier', 'shirt and tie', 'sulfa', 'snowboarder', 'restaurant', 'chicken and vegetables', 'jerrold bennett', 'green, yellow, red', 'paddle', 'wine', 'zebras', '9:00', 'ruffled', 'bright', 'air force', 'station', 'lir', 'umbrella', 'foreground', '753 7264', 'on hull', 'philadelphia', 'green and white', 'hamster', 'stomach', 'net', 'glove', 'diegoforneroit', 'one is standing', 'soft', 'provolone', 'oval', 'tennis court', 'flamingo', 'covers', 'clog', 'lights', 'crop', 'lampshade', 'under skateboarder', 'out of', 'beef', 'ski lifts', 'malamute', 'natural', '106', 'surfboard', 'banana', 'fruit', 'carrots', 'scooter', 'grind', 'upstairs', 'main st', 'shelf', 'cat', 'measuring cup', 'truck', 'rug', 'kitchenaid', 'spoon', 'road trip', 'red sox', 'antelope', 'vegetable', 'go', 'antique', 'tag', '4:15', 'name tag', 'daffodils', 'stainless steel', '118', 'cash fast', '2:42', 'meine-reiseberichtenet', 'mustard', 'genetics', 'athletics', 'pipe', 'paint', 'outdoors', 'beau', 'none', 'sink', 'crouching', '40', 'towels', 'monster trucks', '6:15', '1:30', '5:25', 'big ben', 'tornado', 'front of train', 'polka dot', '0', 'africa', 'shoulder', 'rodeo', 'white', 'next to sink', 'street', 'teeth', 'sprinkles', 'aggies', 'sunflower', 'to north pole', 'background', 'looking in fridge', 'kansas', 'healthy', 'cleaner', 'no pants', 'kia', 'washington', 'rocky', 'beets', 'k roberts photography', 'peacock', 'fries', 'sydney', 'stadium', 'right hand', '573', \"they're walking by it\", 'caucasian', 'keep water in tub', 'hydrant', 'website', 'red', 'cereal', 'towel', 'business model generation', 'above umbrellas', 'carraig donn', 'bottles', 'remote', 'relaxing', 'gothic', 'dump truck', 'road work ahead', 'matadors', 'parade', 'standing still', 'big', 'cooked', 'day', 'away', 'soap', 'ducks', 'singles', 'land', 'no hat', 'downtown chicago', 'nuts', 'anytime', 'boxing', 'waves', 'carpet', 'child put there', 'for comfort', 'blonde', \"you're walking through poetry\", 'required', 'sunny weather', 'catch frisbee', 'frosting', 'on his feet', 'arrows', 'rock', 'playing', 'life jacket', '1.10', 'german', 'red light', 'mud', 'tye dye', 'yellow', 'sherman st', '20 inches', 'airplane', 'bracelet', 'glasses', 'jet', 'race', 'van', 'woman driving', 'sailboat', 'business', 'next train', 'in hand', 'corporate dr', 'vans', 'seattle', 'glazed', 'egg', 'girl and boy', 'near tv', 'wii', 'boys', 'watching', 'not happy', 'pee', 'green', 'oranges', 'plucking eyebrows', 'ox', '4:45', 'blinds', 'sky', 'goats', 'ski lodge', 'no shoes', 'brush hair', 'clouds', 'passenger', 'south african airways', 'starbucks', '90', 'honest man', '34b', 'religious', 'raggedy ann and pooh bear', 'green and red', 'no red letters', \"krusty o's\", 'new', 'stealth', 'taking picture', 'pineapple', 'bathroom', 'ernie', 'tennis racquet', 'khaki', 'gloves', 'squatting', 'field hockey', '3:10', 'feed', 'to get to other side', \"she doesn't\", 'holes', 'outdoor', 'by stream', 'mayo', 'uwe harms & sohn', 'tommy', 'coming', 'iris', 'dollars', 'tennis racket', 'jeter', 'tear gas', 'cloth', 'stone', 'umpire', 'adding ingredients', 'captivity', '16', 'sauce', 'derrick', 'very big', 'roman', 'president st', 't shirt', 'helping', 'sweet dreams', '242', 'snow', 'porcelain', 'sunset', 'housing', '8 st', 'mariners', 'chevrolet', '10000000', 'west', 'playing frisbee', 'vista canyon', 'yes', 'pokemon', 'plum', 'bike handle', 'lots', 'shower', 'paws', 'cupcake', 'it is brown', 'argyle', 'fell out', '22', 'no lights', '6 hours', 'brunette', 'cutting board', 'keyboard', '3:03', 'pink and yellow', 'cups', 'arrested', 'sun hat', 'panting', 'bike ride', 'bull', 'bedroom', 'in shack', 'slow down', 'chives', 'plaid', 'raining', 'phillies', '5:02', 'dust', 'container', 'mammal', 'presenting', 'yellow, blue', 'in back', 'no flowers', '14', 'route 66 harley davidson', 'rose', '6:10', 'ties', 'neon', 'mug', 'train yard', 'latex', 'riding in car', 'stone vs ceramic', 'lemon', 'horse field', 'direct rail services', 'advertisements', 'internet', 'titan', 'clay', 'snowboard', 'orange slice', 'stew', 'living room', 'meter remains as courtesy to cyclists', 'drinking', 'tradition', 'posing for picture', 'to protect from sun', 'pomeranian', 'cheetos', 'sand', 'refrigerator', 'round', 'empty', '5:05', 'cement', 'military', 'entertainment', 'ski lift', 'women', 'tennis player', '10 years', 'trucks', 'boyle heights', 'sandwiches', '2008', 'lighthouse', 'summer', 'pickles', 'rice and broccoli', 'mall', 'magazines', 'horses', 'center stand', 'websites', 'hold cheese', 'long room', 'chopsticks', 'long distance', 'graffiti', 'friend', 'kite', 'crosswalks', 'pirate', 'watermark', 'under counter', '1990', 'flea market', 'backpack', 'neck', 'tennis', 'juggler', 'no train', 'center', '100 feet', 'buses', 'jetblue', 'day time', 'red lobster', '9:59', 'train', 'cover', 'kenya airways', 'no chair', 'address', 'mlb network', 'map', 'shearing', 'north street north end tobin', 'gatorade', 'giraffe', 'husky', 'hang ten', 'dirt on pants', 'person', 'working', 'bowtie', 'inside store', 'pelicans', 'counter', 'banana peppers', 'branding', 'hamburger', 'adidas', 'meme', 'north or south', 'dresses', 'tulip', 'lanyard', 'cloudy', 'lei', 'standing', 'parrot', 'baseball bat', '3 feet', 'no placemat', '38', 'becky mccray', 'british', 'carrying objects', 'loose', 'gamecube and playstation', 'british airways', 'pulling wagon', 'mirror', 'texas', '31', '7sky', 'arm', 'acer', 'nothing', 'lot of traffic', 'ride motorcycle', 'cupcakes', 'playing soccer', 'spider', 'savory', 'square', 'it is called library', '10:22', 'circles', 'stop', \"70's\", 'piano', 'howard', 'drain', 'united', 'ivy', 'express amt', 'roll up', 'wicker', 'jacket', '11:20', 'toothbrush', 'harry potter', 'lazy susan', '6 feet', 'nose', 'left and right', 'toilet', 'food', 'stairs', 'bin', 'berries', '2:40', 'seaplane', 'mutt', 'no entry', '12 feet', '9:30', 'brakes', 'for photo', 'computer', 'bricks', 'steel', 'fedex', 'candles', 'top', 'sweater', 'hard', 'grazing', 'scuffed', 'phones', 'sheep and dog', 'not deep', 'food art', 'half', 'not working', 'daffodil', 'no', 'coat', '5', 'parking', 'what', 'gray and black', 'arrow through circle', 'so he can see', 'mitsubishi', 'chocolate chip', 'dachshund', 'city street', 'swing', 'different ages', 'myer', 'shorts', 'aprons', 'front', 'waffles', 'on far left', 'cookie', 'serious', 'air', 'silver', 'tennis rackets', 'volvo', 'goggles', '2', 'pot', 'racism free', 'tablecloth', 'boxes', 'corn', 'silk', 'sightseeing', 'passengers', 'short', 'reflection', 'hoodie', '450', 'suitcase', 'chicago', 'planes', 'suburban', 'barrel', 'weeds', 'dessert', 'sun', 'clothing', 'week', 'windmills', 'hazy', '4 wheeler', 'terrier', 'no beets', 'visor', 'chicken', 'teal', 'football', 'barrier', 'oven drawer', 'propellers', 'statues', 'sheep', 'harley', 'british united', 'traffic lights', 'bears', 'plums', 'dundas st w', 'directions', 'cave', 'on sandwich', \"don't get hit by ball\", '2010', 'gucci', 'wristbands', 'chairs', 'new orleans', 'canada', 'mercedes', 'dock', 'just took off', 'probefahrt', 'iron', '.99 lb', 'venetian', 'flip', 'frisbee', 'pink', 'sausage', 'street sign', '023236', 'finger', 'dark', 'ted', 'lot', 'words', 'in snow', '29', 'waving', '928', 'trees', 'meditating', 'dress', 'on right', 'snoopy', 'umbrellas', '200', 'shade', 'roll', 'person seated', '2.5 meters', 'pizza dough', 'red and black', 'years ago', 'skeleton', 'brown', 'selling', 'bikes', 'staring', 'mouse', '1 big bus', 'fire hydrant', 'festival', 'straight', '4:55', 'lab', 'salmon run', 'polar bear', 'boundary', 'skateboarder', 'ship', 'bus', 'wii remotes', 'eyelashes', 'under window', 'cross country', 'lichen', 'sunnyside', 'crank', 'hit', 'recycle', 'tater tots', 'woman', 'building sandcastle', 'person in front of it', 'bending', 'rocks', 'knife', 'britain', 'rural', 'to boat', 'scarf', 'cucumber', 'xbox 360', 'reds', '26', 'marble', 'on wall', 'downhill', 'on highway', 'ana', '24', 'army', 'eucalyptus', 'cowboys', 'rack', 'sandwich', 'biplanes', 'baseball', 'skier', 'b', 'sunny', 'convertible', 'on plate', 'bumpers', 'dunkin donuts', 'lady', 'very old', '625', 'globe', 'nike', 'coca cola', '8:54', 'mask', 'vegan', '1900', 'they like to pee on it', 'right', 'cake pops', 'doorway', 'brush', 'elephant', 'goal', 'brace', 'v', 'purple', 'stationary', '18d4329', 'soccer', 'oak', '7:27', 'unsure', 'pies', 'giraffes', 'b6', 'raisin bread', 'cars', 'let you park', 'white brown', 'cooking', 'home plate', 'bossart', 'drop coffee', '64', 'laptops', 'chihuahua', 'leisure', 'logs', 'flowers', 'modern', 'nightlight', 'alienware', 'you cannot pass', 'in coffee', 'at-101', 'traffic merging', 'slow', 'moped', 'skiing', 'boondock saints', 'conductor', 'ceiling light', 'sleep', 'putting out fire', 'hanes', '100 year party ct', 'ski', 'yeah', 'town', 'toothpaste', 'behind clouds', 'goat', 'top shelf', 'lightning bolt', 'futon', 'no house', 'joshua', 'cow', 'one way', 'loading luggage', 'apples', 'spain', 'stop sign', 'addington village', 'fast', 'visibility', 'qbuzz', 'christleton', 'midway', 'kayak', 'cut', 'zodiac', 'surf shop', 'knit', 'dogs', '1', 'lost zoo', 'desert', 'canon', 'on bus', '10:35', 'next to stove', 'behind mother', 'street light', 'onion and sausage', 'fried', '9', 'dhl', 'wild', 'day lane', 'feeding', 'yamaha', 'local traffic only', 'mercedes benz', '18', 'barbara kingsolver', 'microwave', '58', 'on car', 'helmet', 'bumpy', 'nerd', 'toast', 'celery', 'stand', 'lilies', 'direction', 'me', 'spinach', 'yogurt', 'bunk beds', 'necklace', 'universal', '13208', 'upright', 'grandfather', 'cliffs', 'wind', 'advertisement', 'basket', 'beanie', 'dolls', 'blending', 'blue and white', 'mastercard and visa', 'phone and toothbrush', '60', 'in hands', 'farmer', 'human', 'cubs', '27', 'blender', 'wooden', 'cut cake', 'feet', 'up', 'car', 'babies', 'seeds', 'wallet', 'cross', 'getting food', 'fern', 'small plane', 'stuffed animal', 'gravel', 'fork and knife', 'fire', 'stuffed animals', 'red and white', 'easy', 'rowing boat', 'park ave', '30 91', 'top hats', 'real', 'brand', 'to work', 'crumbs', 'not at all', 'visited art', 'flying kite', 'curtain', 'clothes', 'cabinets', 'country', 'teens', 'many', 'baker', 'sign', 'in bed', 'follow your dreams', 'on slope', 'floor', 'no animal', 'tel aviv', 'behind motorcycle', 'peaches', 'rainbow', 'disney', 't', 'sidewalk', 'easyjet', 'on bread', '1/3', 'white and black', 'wilson', 'dry and arid', 'ripe', 'leash', 'baltimore', 'winecopp youth', 'fell', 'kayaks', \"user's guide\", 'delta', 'temperate', 'birds', 'parsley', 'male', '19', 'this 1', 'cabinet', 'rinsing', 'leis', 'cows', 'tartar sauce', 'batting', '7844', 'butt', 'cannot tell', 'shoe', '2 broke girls', 'groceries', 'jerky', 'wine glass', 'tabasco', 'someone', 'spiderman', '5:40', 'typing', '5:18', '4:30', 'ruler', '5:54', 'grizzlies', 'bathtub', 'warning', 'on ground', '4057', 'spatula', 'laundry', 'hanger', 'skull and bone', '8', 'fun', 'power', 'olde city', 'pottery', 'barbed wire', 'anniversary', 'sandals', 'hello kitty', 'fitted', 'rose petals', '14 hours', 'mother and children', 'hammock', 'stick', 'venice', 'green and gray', 'pekingese', '86753', '68', 'x', 'paper bag', 'pulled pork', 'return to newcis wrexham', 'knees', 'king monkey', 'little high', 'cream and red', 'c', 'swimming', 'overcast', 'salmon', 'potatoes', 'rear', 'red and orange', 'honda', 'mazda', '7', 'obstacles', 'bun', 'family', 'dozens', 'homemade', 'victoria', 'money', 'semi', 'fish', 'color', 'numbers', 'gabriel', 'steam', 'carrots and celery', 'japan airlines', 'cattle', 'softball', 'tube', 'identification', 'parasailing', 'escalator', 'roses', 'asian girl holding teddy bear', 'space needle', '100', 'electric', 'close', 'sauerkraut', 'after', 'looking out window', 'drying', 'wiping', 'trailways', 'earring', 'umpiring', 'washington dc', 'hit baseball', '123', 'bag over head', 'press conference', 'crayons', 'smile', 'temperature', 'record player', 'kitesurfing', 'suit', 'coins', 'far right', 'outfield', 'historical', 'mozzarella', 'orange and blue', 'shortland', 'everyday', 'july', 'stove door', 'blue', 'shallow', 'farmers market', 'grizzly', 'turf', 'work', '365', 'female', 'picture', '5288', 'ham', 'pitcher', 'tv show', '3 for $1', 'tata hispano', 'girl', 'gas', 'bacon', 'on legs', 'seagulls', 'scania', 'pete', 'little', 'tea', '2 feet', 'mexico', 'applegate farms', 'cheese and basil', '7:57', 'two signs', 'polaroid', \"he's not\", 'cutting cake', 'blue and pink', 'usa', 'silverware', 'size', 'cliff', 'left', 'mountains', '80', 'joe biden', 'flintstones', 'historical significance', 'desk', 'portrait', 'refereeing', 'confetti', '17', 'it is getting dark', 'unknown', 'offering', '3:20', 'wire', 'fridge', 'scissors', 'made', 'concentration', 'using computer', 'video game', 'oxen', 'catching', 'delivery', 'windsor', 'behind', '3:30', 'jfk', 'on green sign', 'coach', '88', '1/4', 'london buses', 'rockaway beach', 'for 2 people', 'thin', 'casual', 'blue and yellow', '7177', 'wine bottle', 'pinky', 'fire hydrant and drinking fountain', 'to catch ball', 'soldier', 'time of day', 'hot', 'no ball', 'sweet', 'windmill', 'weather vane', 'dresser', 'no picture', 'shingle', '3 inches', 'watch', 'jones', 'guitar', 'acoustic', 'gold', 'english', 'puppet', 'cactus', 'flag', 'couch', 'on napkin', 'posing', 'bread', 'singing', 'double decker', 'clip', '12:15', 'traffic', 'injured', 'on stove', 'kings ave', 'cap gun', 'skateboard park', '10:20', 'home', 'jungle', 'dump', 'police notice no stopping on this road', 'regio', 'same color', 'happy', 'earrings', 'zebra', 'himself', 'donut', 'subway', 'its warm', 'nice', 'rings', 'knee pads', 'safari', 'under', \"i don't know\", 'cauliflower', 'police horse', 'boogaloos', 'jeep', 'jet engines', 'no strap', 'fence', 'tow truck', 'hill', '43', 'movement', 'sleeveless', 'black', '23:58', 'acura', 'catching frisbee', 'vanilla', 'london, new york, berlin, tokyo', 'next to dog', 'curtains', 'strike', 'hampton boston', 'chain', '055', 'red, white, blue', 'catering', 'us', 'apprentice', 'cook', 'in his hands', 'younger', 'dimes', 'saint-mathieu and baile', 'shell', 'bowl', 'cold', 'harley davidson', '28', 'proctor', 'pigtails', 'miami', 'art', 'golden retriever', 'roof', 'not long', 'cross traffic does not stop', 'decorative', 'doritos', 'players', 'jousting', 'scottish', 'glover park', 'black and white', 'chips', 'blue and red', '2:45', 'wedding', 'headband', 'harness', 'tortilla', 'by window', 'dirty', 'flip flops', 'at camera', 'cilantro', 'choppy', '3', 'trdelnik', 'building', 'green and yellow', 'back of toilet', 'melted', 'tweet', 'apple, orange, lemon, kiwi', 'easily', 'no parking in aisles', 'daisies', 'piranha', 'trip', 'smartphone', '5:30', 'donkey', 'love', '2:33', '12:34', 'cleaning itself', 'card', 'thumb', 'michelin', '12:33', 'wontons', 'seeing', 'pavement', 'riding', 'toilet paper', 'cheap', 'tuna', 'pine', 'green trash baskets', 'labrador', 'bench', 'bike', 'on stand', 'cleaning', 'oasis and wonderland', 'sunglasses', 'vines', 'helmets', 'hand', 'betsy', 'on tower', 'pickle', 'mango and watermelon', 'drying it', 'not possible', 'black and pink', 'red and yellow', 'premo', 'left drawer', 'yellow and white', 'humped zebra crossing', 'wwwmyprofecom', 'ubuntu', 'star', 'lawyer', 'caboose', 'to get attention', 'sunny side up', '4', 'vaio', 'american', 'closed', 'thumb control', 'on road', 'badminton', 'circle', 'high fiving', 'bagel', 'vattenfall', 'yellow and blue', '20', 'to wear', 'long', 'pabst blue ribbon', 'by house', 'trailer', 'pacific ave', 'phone', 'first', '23', 'back', 'faucet', 'hat', 'baby', '12:00', 'kitchen', 'railroad crossing', 'solid', 'warszawa', 'produce', 'on couch', 'office', 'cup', 'ginger', 'flying kites', 'bathroom sink', 'not get dirty', 'fisheye', 'suv', 'electricity', 'emergency lights', 'shingles', 'texting', 'stroller', 'sonderwagen', 'measuring dog', 'beige', 'cones', 'pug', 'parson street', 'both', '127', 'coffee pot', 'microphone', 'mustache', 'camera', 'woman in jeans', 'badge', 'purse', 'middle', 'polo', 'ukraine', '12', 'leg', 'traffic control', '7:25', 'tags', 'chinese', 'tow', 'uk', '3:18', 'white black', 'cats', 'this vehicle', 'fruit stand', 'protection', 'suzuki', 'strawberries, blueberries, kiwi and oranges', 'sneakers', 'lax', 'boston', 'elvertbarnescom/mixology', 'coworkers', 'parachute', 'united states', 'sharp', 'play', 'hungry', 'adria', 'ak', 'legal service', 'italian', '78', 'ipad', 'supreme', 'boating', 'edmunds', 'brick', 'blue moon', 'apple and banana', 'christmas', 'in stands', 'bed', 'giraffe ate them', 'smoke', '100% grape seed oil', 'poop', 'kite flying', 'jeans', 'vitamin c', 'boy', 'nintendo', 'bad', 'forward', 'broccoli carrot', 'rue croix des petits champs', '1 week', 'k', 'heinz', 'face', 'tank top', 'bell', 'fabric', 'n6594q', 'foggy', 'denim', 'lace', 'talking on phone', 'adult', 'california berkeley', 'packers', 'hanging on fence', 'china', 't-shirt', 'father and daughter', 'deep', 'behind truck', \"that's way it was made\", 'wedding cake', 'poodle', 'bridle', 'throwing', 'rain', 'rice, olives, broccoli, beans, peas, corn and carrots', 'plants', 'picking up passengers', 'caramel', 'minnesota', 'pocket', 'war', 'shelves', 'meow', 'manhole', 'leaf', 'poster', 'mushrooms', 'milk', 'wall', 'chandelier', 'pacifier', 'white and blue', 'coke', 'chevy', 'cat and dog', 'road closed', 'samsung', 'reused', 'ride', 'rope', 'screen', 'teddy', 'in bowl', 'lookout', 'bento', 'manhole cover', 'platform', 'utensil holder', 'new york', '9:50', 'tarmac', 'one on right', 'broken', 'people walking', '7:50', 'pistoia', 'halloween', 'a', 'bow', '10:25', '12:51', 'shells', 'friendship', '24 inches', 'zebroid', 'emergency', 'yellow and red', 'leaves', 'christian', '158 799', 'jets', 'sweeping', 'captain', \"valentine's day\", 'on skateboard', 'train cake', 'india', 'fireman', 'african', '33', 'light pole', 'air france', 'sony', 'jay d rogers', 'vase', 'pliers', 'fire truck', 'blue and green', 'main', 'medium', 'train tracks', 'tomato', 'usa and bangladesh', 'ketchup', 'airbus', 'door', 'windshield wipers', 'pancakes', 'duck', 'mark place for fans', 'abstract', 'church', 'john', 'hot sauce', 'bridge', 'lantern', 'ace', 'music', 'spiral', 'sour', 'mouth', 'rhino and zebra', 'blanket', 'skis', 'barack obama', 'sports', 'c-gtad', 'ikea', 'sugar', 'north', 'hat and coat', 'morning', 'schrader', 'peanut butter', 'golden gate', 'waiting', 'shore', 'white city', 'toaster oven', 'green and brown', 'taking pictures', 'calm', 'speed of serve', 'brussels airlines', 'crows', 'stool', 'pepper', 'ddb', 'hawaiian', '25', 'cheese', 'safety', 'riding moped', 'market', 'pm', 'motorcycle', 'ocean', 'driveway', '27489826', 'hats', 'cole slaw', 'luggage', 'show', 'milk cans', 'listening', '15', '45', 'x64', 'cigarette butts', 'trash', 'concrete', 'death for', 'whale', 'no uniforms', 'box on screen', 'hair dryer', '180', 'grapes, apples, bananas', 'forest', 'headphones', 'tan', 'pin', 'inside', 'pigeons', 'france', 'south', '11:19', \"don't know\", 'carriage', 'seaweed', 'obama', 'broccoli', 'ball boy', '01', 'activia', 'on top of building', 'statue'}\n",
            "Number of training classes: 2522\n",
            "Number of validation samples: 2663\n",
            "Number of test samples: 2660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "dU2IrxY-rXTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transformations\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "#image_transforms = transforms.Compose(\n",
        "#    [transforms.Resize((224, 224)), transforms.ToTensor(), normalize]\n",
        "#)\n",
        "eval_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "image_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Fh2GPpxzrYWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset and dataloader"
      ],
      "metadata": {
        "id": "nbmuKHKWrZcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VQADataset(Dataset):\n",
        "    def __init__(self, images, questions, answers, transform=None):\n",
        "        self.images = images\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        question = torch.tensor(self.questions[idx], dtype=torch.long)\n",
        "        answer = torch.tensor(self.answers[idx], dtype=torch.long)\n",
        "        return image, question, answer\n",
        "\n",
        "train_dataset = VQADataset(\n",
        "    train_selected_images,\n",
        "    train_padded_questions,\n",
        "    train_answer_classes,\n",
        "    transform=image_transforms,\n",
        ")\n",
        "\n",
        "val_dataset = VQADataset(\n",
        "    val_filtered_images,\n",
        "    val_padded_questions,\n",
        "    val_answer_classes,\n",
        "    transform=eval_transforms,\n",
        ")\n",
        "\n",
        "test_dataset = VQADataset(\n",
        "    test_filtered_images,\n",
        "    test_padded_questions,\n",
        "    test_answer_classes,\n",
        "    transform=eval_transforms,\n",
        ")\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "test_data_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "W9oFSUpOrbuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model architecture"
      ],
      "metadata": {
        "id": "U-PUu4tOrecO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, image_dim, text_dim, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.image_att = nn.Linear(image_dim, hidden_dim)\n",
        "        self.text_att = nn.Linear(text_dim, hidden_dim)\n",
        "        self.final_att = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(p=0.1)  # Dropout after attention layer\n",
        "\n",
        "    def forward(self, image_feats, text_feats):\n",
        "        img_att = self.image_att(image_feats)  # [batch_size, num_pixels, hidden_dim]\n",
        "        txt_att = self.text_att(text_feats)    # [batch_size, hidden_dim]\n",
        "        combined_att = F.relu(img_att + txt_att.unsqueeze(1))  # Add text feats to each image feat\n",
        "        #combined_att = self.dropout(combined_att)  # Dropout\n",
        "        att_scores = F.softmax(self.final_att(combined_att), dim=1)  # [batch_size, num_pixels, 1]\n",
        "        weighted_feats = (image_feats * att_scores).sum(dim=1)  # [batch_size, image_dim]\n",
        "        return weighted_feats\n",
        "\n",
        "class VQAModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_answers, image_feature_dim):\n",
        "        super(VQAModel, self).__init__()\n",
        "\n",
        "        # Initialize the ResNet model\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])  # Use layers up to the last convolutional layer\n",
        "\n",
        "        # Additional layer to pool image features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Pool to 1x1 feature per channel\n",
        "\n",
        "        # Attention Layer\n",
        "        self.attention = Attention(image_dim=image_feature_dim, text_dim=hidden_size, hidden_dim=512)\n",
        "\n",
        "        # Text processing layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
        "        self.dropout_lstm = nn.Dropout(p=0.5)  # Dropout after LSTM\n",
        "\n",
        "        # Classifier\n",
        "        self.fc1 = nn.Linear(hidden_size + image_feature_dim, 512)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(512, num_answers)\n",
        "\n",
        "    def forward(self, images, questions):\n",
        "        # Extract image features\n",
        "        img_features = self.resnet(images)  # [batch_size, channels, height, width]\n",
        "        img_features = self.avgpool(img_features)  # Pool features\n",
        "        img_features = img_features.view(img_features.size(0), -1)  # Flatten to [batch_size, channels]\n",
        "\n",
        "        # Process the text\n",
        "        embedded = self.embedding(questions)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        lstm_out = self.dropout_lstm(lstm_out)\n",
        "        question_repr = lstm_out[:, -1]\n",
        "\n",
        "        # Apply attention\n",
        "        attended_img_feats = self.attention(img_features, question_repr)\n",
        "\n",
        "        # Classifier\n",
        "        combined = torch.cat([attended_img_feats, question_repr], dim=1)\n",
        "        x = self.fc1(combined)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Model initialization\n",
        "VQA_NET = VQAModel(\n",
        "    vocab_size=len(tokenizer.word_index) + 1,\n",
        "    embed_size=256,\n",
        "    hidden_size=512,\n",
        "    num_answers=len(train_classes),\n",
        "    image_feature_dim=2048\n",
        ")"
      ],
      "metadata": {
        "id": "xhYsoVusrf4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de4e888-34d8-4c3a-9649-55bb7d50c899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(VQA_NET)"
      ],
      "metadata": {
        "id": "Emk5DeSQqVRI",
        "outputId": "f8be1c03-61f4-4b6f-b984-8f31eb9a0c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VQAModel(\n",
            "  (resnet): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (attention): Attention(\n",
            "    (image_att): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (text_att): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (final_att): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (embedding): Embedding(4805, 256)\n",
            "  (lstm): LSTM(256, 512, batch_first=True)\n",
            "  (dropout_lstm): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=2560, out_features=512, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=512, out_features=2522, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation"
      ],
      "metadata": {
        "id": "VqBKGjw-rhXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "question_types = ['what', 'where', 'how many', 'which', 'is there', 'does the', 'are there']\n",
        "\n",
        "def identify_question_type(question):\n",
        "    for q_type in question_types:\n",
        "        if question.lower().startswith(q_type):\n",
        "            return q_type\n",
        "    return 'other'\n",
        "\n",
        "# Function for Gradient Clipping\n",
        "def clip_gradients(model, clip_value):\n",
        "    parameters = [p for p in model.parameters() if p.grad is not None]\n",
        "    for p in parameters:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "\n",
        "# Function for Learning Rate Decay\n",
        "def adjust_learning_rate(optimizer, epoch, decay_rate, initial_lr):\n",
        "    lr = initial_lr * (decay_rate ** epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "    recall = recall_score(true_labels, predicted_labels, average=\"weighted\", labels=np.unique(predicted_labels))\n",
        "    f1 = f1_score(true_labels, predicted_labels, average=\"weighted\", labels=np.unique(predicted_labels))\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Function to convert tensor to image\n",
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor.cpu().clone()\n",
        "    tensor = tensor.squeeze(0)\n",
        "    tensor = unnormalize(tensor)\n",
        "    tensor = tensor.numpy().transpose(1, 2, 0)\n",
        "    tensor = np.clip(tensor, 0, 1)\n",
        "    return tensor\n",
        "\n",
        "# Unnormalize function\n",
        "def unnormalize(tensor):\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)    # unnormalize\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "RKIm9IRvrhA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single split training/validation"
      ],
      "metadata": {
        "id": "2r3CVPYQrkfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import sklearn.exceptions\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import csv\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
        "\n",
        "# Training Parameters\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.001\n",
        "DECAY_FACTOR = 0.999\n",
        "WEIGHT_DECAY = 0.001\n",
        "CRITERION = nn.CrossEntropyLoss()\n",
        "OPTIMIZER = optim.Adam(VQA_NET.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "VQA_NET.to(device)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "wait = 0\n",
        "\n",
        "# Initialize storage for predictions and labels by category\n",
        "category_predictions = {q_type: [] for q_type in question_types}\n",
        "category_true_labels = {q_type: [] for q_type in question_types}\n",
        "\n",
        "for epoch in range(1,EPOCHS+1):\n",
        "\n",
        "    # Training phase\n",
        "    VQA_NET.train()\n",
        "    adjust_learning_rate(OPTIMIZER, epoch, DECAY_FACTOR, LEARNING_RATE)\n",
        "    total_loss = 0.0\n",
        "    for i, (images, questions, labels) in enumerate(train_data_loader):\n",
        "        images, questions, labels = images.to(device), questions.to(device), labels.to(device)\n",
        "        OPTIMIZER.zero_grad()\n",
        "        outputs = VQA_NET(images, questions)\n",
        "        loss = CRITERION(outputs, labels)\n",
        "        loss.backward()\n",
        "        #clip_gradients(VQA_NET, 10)  # Gradient clipping\n",
        "        OPTIMIZER.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Avg train loss\n",
        "    avg_loss = total_loss / len(train_data_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    VQA_NET.eval()\n",
        "\n",
        "    all_pred_labels = []\n",
        "    all_true_labels = []\n",
        "    total_val_loss = 0.0\n",
        "    correct_answers = 0\n",
        "    total_answers = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, questions, labels in val_data_loader:\n",
        "            images, questions, labels = images.to(device), questions.to(device), labels.to(device)\n",
        "            outputs = VQA_NET(images, questions)\n",
        "            loss = CRITERION(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_answers += (predicted == labels).sum().item()\n",
        "            total_answers += labels.size(0)\n",
        "            _, predicted_labels = torch.max(outputs, dim=1)\n",
        "            all_pred_labels.extend(predicted_labels.cpu().numpy())\n",
        "            all_true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Evaluate validation performance after each epoch\n",
        "    current_val_loss = total_val_loss\n",
        "    if current_val_loss < best_val_loss:\n",
        "        best_val_loss = current_val_loss\n",
        "        best_epoch = epoch\n",
        "        wait = 0  # Reset wait time if there's an improvement\n",
        "        # Save the model checkpoint if this is the best model so far\n",
        "        torch.save(VQA_NET.state_dict(), f'/content/drive/MyDrive/Deep_learning/model_states/new_model_baseline{epoch}.pth')\n",
        "    else:\n",
        "        wait += 1  # Increment wait time if no improvement\n",
        "\n",
        "    # Scheduler update\n",
        "    SCHEDULER.step(current_val_loss)\n",
        "\n",
        "    # Compute and display metrics\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(all_true_labels, all_pred_labels)\n",
        "    print(f\"Epoch [{epoch}/{EPOCHS}] | Training Loss: {avg_loss:.4f}, Validation Loss: {current_val_loss:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Write results to file for analysis later\n",
        "    with open('/content/drive/MyDrive/Deep_learning/epoch_statistics_baseline.csv', 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([epoch, avg_loss, current_val_loss, accuracy, precision, recall, f1])\n",
        "\n",
        "    # Early stopping check\n",
        "    if wait >= patience:\n",
        "        print(f\"Stopping early at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "# Load in best model\n",
        "if current_val_loss!=best_val_loss:\n",
        "    print(f'Loading model from epoch: {best_epoch}.')\n",
        "    VQA_NET.load_state_dict(torch.load(f'/content/drive/MyDrive/Deep_learning/model_states/new_model_baseline{best_epoch}.pth'))"
      ],
      "metadata": {
        "id": "c20QE1MvrmLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25350952-bdc0-4b77-b14f-839ea28b0d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] | Training Loss: 4.3391, Validation Loss: 136.0140\n",
            "Accuracy: 0.2561, Precision: 0.1182, Recall: 0.5194, F1 Score: 0.3044\n",
            "Epoch [2/100] | Training Loss: 3.8428, Validation Loss: 132.4094\n",
            "Accuracy: 0.2730, Precision: 0.1151, Recall: 0.5215, F1 Score: 0.3034\n",
            "Epoch [3/100] | Training Loss: 3.7455, Validation Loss: 128.7316\n",
            "Accuracy: 0.2749, Precision: 0.2294, Recall: 0.4738, F1 Score: 0.3202\n",
            "Epoch [4/100] | Training Loss: 3.6637, Validation Loss: 125.2263\n",
            "Accuracy: 0.2918, Precision: 0.1246, Recall: 0.7961, F1 Score: 0.4669\n",
            "Epoch [5/100] | Training Loss: 3.5741, Validation Loss: 123.1397\n",
            "Accuracy: 0.2843, Precision: 0.1187, Recall: 0.5160, F1 Score: 0.2972\n",
            "Epoch [6/100] | Training Loss: 3.5142, Validation Loss: 120.4520\n",
            "Accuracy: 0.2903, Precision: 0.2313, Recall: 0.4763, F1 Score: 0.3891\n",
            "Epoch [7/100] | Training Loss: 3.4602, Validation Loss: 119.9377\n",
            "Accuracy: 0.2884, Precision: 0.1578, Recall: 0.4964, F1 Score: 0.2876\n",
            "Epoch [8/100] | Training Loss: 3.4153, Validation Loss: 119.3810\n",
            "Accuracy: 0.2899, Precision: 0.1334, Recall: 0.4930, F1 Score: 0.3037\n",
            "Epoch [9/100] | Training Loss: 3.3705, Validation Loss: 119.3955\n",
            "Accuracy: 0.2895, Precision: 0.2001, Recall: 0.4642, F1 Score: 0.2807\n",
            "Epoch [10/100] | Training Loss: 3.3332, Validation Loss: 117.4260\n",
            "Accuracy: 0.2963, Precision: 0.1319, Recall: 0.4858, F1 Score: 0.2873\n",
            "Epoch [11/100] | Training Loss: 3.2974, Validation Loss: 116.3536\n",
            "Accuracy: 0.3000, Precision: 0.2337, Recall: 0.4863, F1 Score: 0.3174\n",
            "Epoch [12/100] | Training Loss: 3.2573, Validation Loss: 115.4984\n",
            "Accuracy: 0.2955, Precision: 0.1392, Recall: 0.4557, F1 Score: 0.2840\n",
            "Epoch [13/100] | Training Loss: 3.2278, Validation Loss: 115.2048\n",
            "Accuracy: 0.2906, Precision: 0.1529, Recall: 0.4799, F1 Score: 0.2875\n",
            "Epoch [14/100] | Training Loss: 3.1994, Validation Loss: 115.0777\n",
            "Accuracy: 0.2925, Precision: 0.1463, Recall: 0.6086, F1 Score: 0.3894\n",
            "Epoch [15/100] | Training Loss: 3.1523, Validation Loss: 113.8026\n",
            "Accuracy: 0.2873, Precision: 0.2381, Recall: 0.4484, F1 Score: 0.2898\n",
            "Epoch [16/100] | Training Loss: 3.1284, Validation Loss: 114.3810\n",
            "Accuracy: 0.2989, Precision: 0.1354, Recall: 0.4836, F1 Score: 0.2945\n",
            "Epoch [17/100] | Training Loss: 3.0980, Validation Loss: 114.2042\n",
            "Accuracy: 0.2989, Precision: 0.1351, Recall: 0.7552, F1 Score: 0.4569\n",
            "Epoch [18/100] | Training Loss: 3.0709, Validation Loss: 113.5009\n",
            "Accuracy: 0.2967, Precision: 0.1579, Recall: 0.4338, F1 Score: 0.2646\n",
            "Epoch [19/100] | Training Loss: 3.0464, Validation Loss: 112.6807\n",
            "Accuracy: 0.3034, Precision: 0.1470, Recall: 0.4557, F1 Score: 0.2830\n",
            "Epoch [20/100] | Training Loss: 3.0126, Validation Loss: 112.5030\n",
            "Accuracy: 0.2933, Precision: 0.2407, Recall: 0.4254, F1 Score: 0.3027\n",
            "Epoch [21/100] | Training Loss: 2.9899, Validation Loss: 113.5150\n",
            "Accuracy: 0.2929, Precision: 0.2576, Recall: 0.4228, F1 Score: 0.2680\n",
            "Epoch [22/100] | Training Loss: 2.9543, Validation Loss: 112.6343\n",
            "Accuracy: 0.3015, Precision: 0.1399, Recall: 0.4251, F1 Score: 0.2602\n",
            "Epoch [23/100] | Training Loss: 2.9441, Validation Loss: 113.9089\n",
            "Accuracy: 0.3057, Precision: 0.2601, Recall: 0.4362, F1 Score: 0.3806\n",
            "Epoch [24/100] | Training Loss: 2.9268, Validation Loss: 112.1546\n",
            "Accuracy: 0.2974, Precision: 0.2531, Recall: 0.4347, F1 Score: 0.2950\n",
            "Epoch [25/100] | Training Loss: 2.8947, Validation Loss: 112.2927\n",
            "Accuracy: 0.2903, Precision: 0.2400, Recall: 0.4370, F1 Score: 0.2803\n",
            "Epoch [26/100] | Training Loss: 2.8667, Validation Loss: 113.3467\n",
            "Accuracy: 0.2955, Precision: 0.2338, Recall: 0.4707, F1 Score: 0.3377\n",
            "Epoch [27/100] | Training Loss: 2.8571, Validation Loss: 112.4207\n",
            "Accuracy: 0.2982, Precision: 0.2359, Recall: 0.4732, F1 Score: 0.3014\n",
            "Epoch 00028: reducing learning rate of group 0 to 9.7237e-05.\n",
            "Epoch [28/100] | Training Loss: 2.8359, Validation Loss: 113.0559\n",
            "Accuracy: 0.3030, Precision: 0.2396, Recall: 0.4400, F1 Score: 0.2679\n",
            "Epoch [29/100] | Training Loss: 2.8224, Validation Loss: 111.9043\n",
            "Accuracy: 0.3038, Precision: 0.1694, Recall: 0.4147, F1 Score: 0.2752\n",
            "Epoch [30/100] | Training Loss: 2.7948, Validation Loss: 111.5125\n",
            "Accuracy: 0.3042, Precision: 0.2103, Recall: 0.4199, F1 Score: 0.2746\n",
            "Epoch [31/100] | Training Loss: 2.7904, Validation Loss: 113.1016\n",
            "Accuracy: 0.2978, Precision: 0.2708, Recall: 0.4273, F1 Score: 0.2915\n",
            "Epoch [32/100] | Training Loss: 2.7710, Validation Loss: 113.0348\n",
            "Accuracy: 0.3000, Precision: 0.2489, Recall: 0.4449, F1 Score: 0.2843\n",
            "Epoch [33/100] | Training Loss: 2.7469, Validation Loss: 112.3433\n",
            "Accuracy: 0.3087, Precision: 0.2226, Recall: 0.4270, F1 Score: 0.2818\n",
            "Epoch 00034: reducing learning rate of group 0 to 9.6656e-05.\n",
            "Epoch [34/100] | Training Loss: 2.7486, Validation Loss: 112.9293\n",
            "Accuracy: 0.3094, Precision: 0.2755, Recall: 0.4540, F1 Score: 0.3451\n",
            "Epoch [35/100] | Training Loss: 2.7129, Validation Loss: 112.6555\n",
            "Accuracy: 0.2985, Precision: 0.2510, Recall: 0.4499, F1 Score: 0.3507\n",
            "Stopping early at epoch 35\n",
            "Loading model from epoch: 30.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-822d5166dc23>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcurrent_val_loss\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mbest_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loading model from epoch: {best_epoch}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mVQA_NET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/Deep_learning/model_states/new_model_baseline{best_epoch}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Deep_learning/model_states/new_model_baseline30.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VQA_NET.load_state_dict(torch.load(f'/content/drive/MyDrive/Deep_learning/model_states/new_model_rcnn{29}.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSt0JqWWNT1P",
        "outputId": "fd26e9ec-8c80-4bde-b42a-adfbb0c8fed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "iDL5ilB6rn_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics for best model"
      ],
      "metadata": {
        "id": "dkzxNWg3rq4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the metrics for the best model\n",
        "accuracy, precision, recall, f1 = calculate_metrics(all_true_labels, all_pred_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "rKxfB2FSrnz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff036fe-2012-41e9-daab-5706a623cf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2985, Precision: 0.2510, Recall: 0.4499, F1 Score: 0.3507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation analysis on test data"
      ],
      "metadata": {
        "id": "pSsN4mI2rtld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def categorize_answer(answer):\n",
        "    if answer.lower() in [\"yes\", \"no\"]:\n",
        "        return \"yes/no\"\n",
        "    if answer.isdigit():\n",
        "        return \"numbers\"\n",
        "    return \"others\"\n",
        "\n",
        "# Initialize storage for predictions and labels by category\n",
        "category_metrics = {\n",
        "    \"yes/no\": {\"true_labels\": [], \"predicted_labels\": []},\n",
        "    \"numbers\": {\"true_labels\": [], \"predicted_labels\": []},\n",
        "    \"others\": {\"true_labels\": [], \"predicted_labels\": []},\n",
        "    \"overall\": {\"true_labels\": [], \"predicted_labels\": []}\n",
        "}\n",
        "\n",
        "# Example usage\n",
        "num_samples_to_display = 15\n",
        "samples_displayed = 0\n",
        "\n",
        "test_pred_labels = []\n",
        "test_true_labels = []\n",
        "total_test_loss = 0.0\n",
        "correct_answers = 0\n",
        "total_answers = 0\n",
        "\n",
        "VQA_NET.eval()\n",
        "with torch.no_grad():\n",
        "    for images, questions, labels in test_data_loader:\n",
        "        images, questions, labels = images.to(device), questions.to(device), labels.to(device)\n",
        "        outputs = VQA_NET(images, questions)\n",
        "        loss = CRITERION(outputs, labels)\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_answers += (predicted == labels).sum().item()\n",
        "        total_answers += labels.size(0)\n",
        "        _, predicted_labels = torch.max(outputs, dim=1)\n",
        "        test_pred_labels.extend(predicted_labels.cpu().numpy())\n",
        "        test_true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Categorize answers and store results\n",
        "        for true_label, predicted_label in zip(labels.cpu().numpy(), predicted_labels):\n",
        "            true_answer = label_encoder.inverse_transform([true_label])[0]\n",
        "            predicted_answer = label_encoder.inverse_transform([predicted_label.cpu()])[0]\n",
        "            category = categorize_answer(true_answer)\n",
        "            category_metrics[category][\"true_labels\"].append(true_label)\n",
        "            category_metrics[category][\"predicted_labels\"].append(predicted_label)\n",
        "            category_metrics[\"overall\"][\"true_labels\"].append(true_label)\n",
        "            category_metrics[\"overall\"][\"predicted_labels\"].append(predicted_label)\n",
        "\n",
        "        \"\"\"\n",
        "        for i in range(images.size(0)):\n",
        "            if samples_displayed >= num_samples_to_display:\n",
        "                break\n",
        "\n",
        "            image = tensor_to_image(images[i])\n",
        "            question_text = ' '.join([tokenizer.index_word.get(idx, '?') for idx in questions[i].tolist() if idx != 0])\n",
        "            true_answer_text = label_encoder.inverse_transform([labels[i].item()])[0]\n",
        "            predicted_answer_text = label_encoder.inverse_transform([predicted[i].item()])[0]\n",
        "\n",
        "            \"\"Display the image with the question and predicted answer.\"\"\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Q: {question_text}\\nTrue: {true_answer_text}, Predicted: {predicted_answer_text}\")\n",
        "            plt.show()\n",
        "\n",
        "            samples_displayed += 1\n",
        "\"\"\"\n",
        "\n",
        "# Compute and display metrics for each category\n",
        "for category, data in category_metrics.items():\n",
        "    print(category)\n",
        "    #print(data['true_labels'])\n",
        "    # Convert each tensor in the list to a NumPy array\n",
        "    predicted_labels_cpu = [label.cpu().numpy() for label in data['predicted_labels']]\n",
        "    # Flatten the list of arrays and then apply inverse_transform\n",
        "    #print(label_encoder.inverse_transform(predicted_labels_cpu))\n",
        "\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(data[\"true_labels\"], predicted_labels_cpu)\n",
        "    print(f\"Category: {category} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rx4ZrrXVrnxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a037ae-3442-4a63-8421-ab6ec33b6e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes/no\n",
            "Category: yes/no - Accuracy: 0.5071, Precision: 0.2603, Recall: 0.5071, F1 Score: 0.3440\n",
            "numbers\n",
            "Category: numbers - Accuracy: 0.2278, Precision: 0.2370, Recall: 0.3083, F1 Score: 0.2062\n",
            "others\n",
            "Category: others - Accuracy: 0.1300, Precision: 0.0803, Recall: 0.2779, F1 Score: 0.1754\n",
            "overall\n",
            "Category: overall - Accuracy: 0.3038, Precision: 0.1694, Recall: 0.4147, F1 Score: 0.2752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88yTFlTyZWPY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}