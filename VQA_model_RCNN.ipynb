{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkXb-uJAdeKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81cedca-690b-4927-cf87-b032950bbdc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch '/content/drive/MyDrive/Deep_learning/epoch_statistics_rcnn.csv'"
      ],
      "metadata": {
        "id": "ds1I7SC5C_cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/drive/MyDrive/Deep_learning/model_states'\n",
        "!mkdir '/content/drive/MyDrive/Deep_learning/data'"
      ],
      "metadata": {
        "id": "BAGvX7hIDDin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6bae6b-2726-4ab9-8637-2e2c8585a1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Deep_learning/model_states’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Deep_learning/data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Deep_learning/data.zip'"
      ],
      "metadata": {
        "id": "x_DuWtUETSAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "mm1mex8qrB2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "tJNiMFFaq5FG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f2b39cb-620f-49b2-8509-b1089ea12e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset and Dataloaders"
      ],
      "metadata": {
        "id": "lHPmHY0ArDrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "SUvOiwH1rHIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training questions and annotations\n",
        "with open(\"data/v2_OpenEnded_mscoco_train2014_questions.json\", \"r\") as file:\n",
        "    train_questions_json = json.load(file)\n",
        "    train_questions = [item[\"question\"] for item in train_questions_json[\"questions\"]]\n",
        "\n",
        "with open(\"data/v2_mscoco_train2014_annotations.json\", \"r\") as file:\n",
        "    train_annotations_json = json.load(file)\n",
        "    train_answers = [\n",
        "        item[\"multiple_choice_answer\"] for item in train_annotations_json[\"annotations\"]\n",
        "    ]\n",
        "\n",
        "# Image paths for training\n",
        "train_image_dir = \"data/train2014/\"\n",
        "train_images = [\n",
        "    os.path.join(train_image_dir, \"COCO_train2014_{:012d}.jpg\".format(item[\"image_id\"]))\n",
        "    for item in train_annotations_json[\"annotations\"]\n",
        "]\n",
        "\n",
        "# Load validation questions and annotations\n",
        "with open(\"data/v2_OpenEnded_mscoco_val2014_questions.json\", \"r\") as file:\n",
        "    val_questions_json = json.load(file)\n",
        "    val_questions = [item[\"question\"] for item in val_questions_json[\"questions\"]]\n",
        "\n",
        "with open(\"data/v2_mscoco_val2014_annotations.json\", \"r\") as file:\n",
        "    val_annotations_json = json.load(file)\n",
        "    val_answers = [\n",
        "        item[\"multiple_choice_answer\"] for item in val_annotations_json[\"annotations\"]\n",
        "    ]\n",
        "\n",
        "# Image paths for validation\n",
        "val_image_dir = \"data/val2014/\"\n",
        "val_images = [\n",
        "    os.path.join(val_image_dir, \"COCO_val2014_{:012d}.jpg\".format(item[\"image_id\"]))\n",
        "    for item in val_annotations_json[\"annotations\"]\n",
        "]"
      ],
      "metadata": {
        "id": "K01oHE7nrGfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare images, questions, answers, and tokenizer"
      ],
      "metadata": {
        "id": "w56Q1NI5rSyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE_TRAIN = 15000\n",
        "train_indices = random.sample(range(len(train_images)), SAMPLE_SIZE_TRAIN)\n",
        "#train_indices = list(range(0, SAMPLE_SIZE_TRAIN-1))\n",
        "train_selected_images = [train_images[i] for i in train_indices]\n",
        "train_selected_questions = [train_questions[i] for i in train_indices]\n",
        "train_selected_answers = [train_answers[i] for i in train_indices]\n",
        "\n",
        "# Select a subset for validation\n",
        "SAMPLE_SIZE_VAL = 3000\n",
        "eval_indices = random.sample(range(len(val_images)), SAMPLE_SIZE_VAL*2)\n",
        "val_indices = eval_indices[:len(eval_indices)//2]\n",
        "test_indices = eval_indices[len(eval_indices)//2:]\n",
        "\n",
        "val_selected_images = [val_images[i] for i in val_indices]\n",
        "val_selected_questions = [val_questions[i] for i in val_indices]\n",
        "val_selected_answers = [val_answers[i] for i in val_indices]\n",
        "\n",
        "test_selected_images = [val_images[i] for i in test_indices]\n",
        "test_selected_questions = [val_questions[i] for i in test_indices]\n",
        "test_selected_answers = [val_answers[i] for i in test_indices]\n",
        "\n",
        "# Find training classes\n",
        "train_classes = set(train_selected_answers)\n",
        "print(f\"Training classes: {train_classes}\")\n",
        "print(f\"Number of training classes: {len(train_classes)}\")\n",
        "\n",
        "# Filter validation answers to include only those present in the training set\n",
        "val_filtered_indices = [i for i, answer in enumerate(val_selected_answers) if answer in train_classes]\n",
        "test_filtered_indices = [i for i, answer in enumerate(test_selected_answers) if answer in train_classes]\n",
        "\n",
        "print(f'Number of validation samples: {len(val_filtered_indices)}')\n",
        "print(f'Number of test samples: {len(test_filtered_indices)}')\n",
        "\n",
        "val_filtered_images = [val_selected_images[i] for i in val_filtered_indices]\n",
        "val_filtered_questions = [val_selected_questions[i] for i in val_filtered_indices]\n",
        "val_filtered_answers = [val_selected_answers[i] for i in val_filtered_indices]\n",
        "\n",
        "test_filtered_images = [test_selected_images[i] for i in test_filtered_indices]\n",
        "test_filtered_questions = [test_selected_questions[i] for i in test_filtered_indices]\n",
        "test_filtered_answers = [test_selected_answers[i] for i in test_filtered_indices]\n",
        "\n",
        "# Merge training and validation questions\n",
        "combined_questions = train_selected_questions + val_filtered_questions + test_filtered_questions\n",
        "\n",
        "# Fit tokenizer on the combined set of questions\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(combined_questions)\n",
        "tokenized_combined_questions = tokenizer.texts_to_sequences(combined_questions)\n",
        "max_question_length = max(len(seq) for seq in tokenized_combined_questions)\n",
        "\n",
        "# Tokenize and pad training questions\n",
        "train_tokenized_questions = tokenizer.texts_to_sequences(train_selected_questions)\n",
        "train_padded_questions = pad_sequences(train_tokenized_questions, maxlen=max_question_length)\n",
        "\n",
        "# Tokenize and pad validation questions\n",
        "val_tokenized_questions = tokenizer.texts_to_sequences(val_filtered_questions)\n",
        "val_padded_questions = pad_sequences(val_tokenized_questions, maxlen=max_question_length)\n",
        "\n",
        "# Tokenize and pad validation questions\n",
        "test_tokenized_questions = tokenizer.texts_to_sequences(test_filtered_questions)\n",
        "test_padded_questions = pad_sequences(test_tokenized_questions, maxlen=max_question_length)\n",
        "\n",
        "# Convert answers to classes\n",
        "label_encoder = LabelEncoder()\n",
        "train_answer_classes = label_encoder.fit_transform(train_selected_answers)\n",
        "\n",
        "# Convert filtered eval answers to classes using label encoder\n",
        "val_answer_classes = label_encoder.transform(val_filtered_answers)\n",
        "test_answer_classes = label_encoder.transform(test_filtered_answers)"
      ],
      "metadata": {
        "id": "BwFX32SnrV3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c2895f-a493-4d77-a820-988a241fb0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classes: {'cell phone', 'ibm', 'aeromexico', 'recycling', 'salmon', 'black and silver', 'on cupboard', 'central', 'arriva', 'twin', \"church's chicken\", 'pineapple', 'bench', 'orange, white and yellow', 'other giraffe', 'family', 'catching', '75', 'mole', 'cucumbers and cheese', 'blue jay', 'italy', 'bricks', 'elephant', 'basketball', 'knife', 'on skateboard', 'no one', 'foreground', 'mess', '12:15', 'construction', 'radical', 'sniffing', 'little bastards', 'wedding', 'bean bag', 'style', 'paper', 'grizzly', '377 303', 'pearl', 'dessert', 'typing', 'shade', 'durham', 'chair', 'hawk', 'hang loose', 'delta', '11', 'egg salad', 'ge', 'cowboy', 'mustangs', 'repeal prop 8', 'knife block', '405', 'tired', '2 inches', 'texting', 'montagut', 'stick', 't and o', 'satellite dish', 'fishing boat', 'reins', 'no alcohol', 'rock', 'blue', '3', 'swans', '1', 'fence', 'chinese', 'orchid', 'game', 'on ski pole', \"it's not\", 'june 10 2010', '3 gx270', 'imac', 'blue team', 'house', 'zebras', 'out of ordinary', 'movie', 'polka dots', \"can't tell\", 'will i am', 'nelson', 'both wearing t shirts', '2012', 'flip flops', 'kmb', 'usa today', 'barbed wire', '38', 'yellow, black', 'butt', 'because of light', 'long haired', 'city district', 'laist hq', 'ultimate', 'skyscrapers', 'not high', 'holding fork', 'plane and bird', 'pencils', 'cabinets', 'elm', 'canal', 'plaid', 'grazing', 'traffic', 'cutting hair', 'boats', 'in cabbage town', 'more room', 'denim', 'superdog', 'figurine', 'hero', '6 am', 'burrito', 'pedestal', 'tea', 'bears', '15', 'rhondda', 'plain', 'singing', 'black, red', 'right side up', 'kids', 'in middle', 'zipster', 'black/white', 'ornaments', 'red, yellow', 'getting sun', 'del monte', '02/05/2013', 'curved', 'handle', 'friday', 'natural gas', 'e', 'on train', 'blowing candles', 'brick', 'numbers', 'diamond', 'sesame', 'air force', 'wet', 'jamaica', 'bathing', 'skipton', 'giants', 'bedroom', 'buoy', '1950', 'owl', 'underarm', 't-shirt and shorts', 'female', 'beets', 'bicycle', 'junk', 'toothbrush', 'salvation army', 'seagull', 'staples', 'tlx', 'pipes', \"90's\", 'magnets', 'jones', 'inside', 'persian', 'tents', 'no table', '4', 'south 95', 'chicago', 'post its', 'on horse', 'doublemint', 'lemonade', 'coaches', 'turn left', 'drew', 'minneapolis', 'no flowers', 'jpmorgancom', 'tennis court', 'soccer player', 'west', 'safety', 'pug', '32', 'h', 'cutting board', 'mans', 'leaping', '54', 'tabby', 'germany', 'putting out fires', 'wool', 'desks', 'shower', 'east st', '14\\'-10\"', 'bikini', '15 and 13', 'steak', 'duck', 'regent', 'smooth', 'cat', 'no book', '1000', 'frame', 'dad', 'roof', 'phillies', 'yes', 'britain', 'lattice', 'bearded', 'barbecue', 'andesmar', '6 ft', 'huge', 'concrete', 'fake', 'woods', '7:58', 'paddington', 'blue and black', 'holiday', 'peppers', 'juice vegetables', '50s', 'blurry', 'copper', 'flags', 'child', 'frosting', 'men', 'stomach', 'cds', 'in bushes', 'parsley', 'girl on right', 'polar bear', 'saddle', 'jump', 'dots', 'dlaord', 'penn station', 'sisak', 'kite flying', 'crane', \"it's dusk\", 'on tray', 'daisies', 'truck route', 'go', '241', 'pedestrian priority crossing ahead', 'bows', 'bathtub', 'rug', '02089630649', 'wii boxing', 'human', 'orange juice', 'laundry', 'knife, fork', 'planter', 'plymouth city', 'poppies', 'front', 'not deep', 'leaving', '2 people', 'pots', 'address', 'tomatoes', \"o'neil\", '10:43', 'trick', 'his sides', 'pink and blue', 'handicap', 'jean king cup', 'no ones', 'cross', 'play wii', 'no stand', 'bmw', 'turf', 'black and white photo', 'steps', 'beko', '2:05', 'wwd', 'snow gear', 'bus and car', 'love trees', 'drivers', 'on sidewalk', 'toilet paper', 'cumulus', 'lady and man', 'white and gray', 'thelonious monk circle', 'linoleum', 'ice cream', 'jfk', 'end', 'commercial', 'furniture', 'deep fried', '502', '1313', 'rangers', 'lawyer', 'cloudy', 'pedestrians', 'fruit', 'sp-kan', 'british united', 'black and gray', 'ford', 'spinach', 'guitar hero', 'buildings', 'over shoulders', 'accident', 'driveway', 'dried up', 'orchard', 'nokia', 'putting in earring', 'tiger', 'vans', 'high', 'prop 8', 'patio', 'yield', 'yellow buses', 'pickles', 'bundt', 'larger', '1:30', 'cskulevold', 'urinal', 'stone vs ceramic', 'on street', 'marble', 'devils', 'accounting', 'menu', 'blue-and-white one', 'wooden', 'molly and annie', 'orange, pineapple, strawberry', 'laptop', 'onions and ketchup', 'swinging', 'teenager', 'spices', 'chef', 'cheese', 'drinks', 'landscape', 'watermelon', 'barbed', '5\\'5\"', 'coffee table', 'in his hand', 'skateboard', \"ed debevic's chicago\", 'on tower', 'by bed', 'no shirt', 'oval', 'texas', 'many colors', 'double decker', 'very big', 'gothic', 'cotton', 'arrows', \"1950's\", 'segway', 'soldiers', 'whistle', 'sunsets', 'gillette', 'on end table', 'peel them', 'runway', '30', 'starting', 'mountie hat', 'eating', 'black and yellow, white', 'entertainment', 'chef hat', 'oars', 'air conditioner', 'bottom left', 'open', 'desktop', 'rainy', 'spraying', '400', 'blinders', 'milka', 'adams morgan', 'park', 'us coast guard', 'google', 'shoulder length', 'play', 'elevator', 'blue shirt', 'soccer players', 'date', 'street', 'happy', 'espn', 'mound', 'one sitting', 'pickup', 'carnations', 'teddy bear', 'jumping', 'british airways', 'cinnamon', 'giving rides', '1950s', 'bats', '12', 'swan', 'canary', 'pen', 'red and blue', 'hit door', 'shut off water', \"so it doesn't scratch its head\", 'make it look holy', 'clockwise', 'table', '1634', 'caution', 'flip phone', 'coasters', '3:33', 'saucers', 'eagle', 'going away', 'creme', 'tropical', 'on tracks', 'eggs, potatoes, pancakes', 'recessed', 'striped', 'wire', 'parade', 'hanging from ceiling', 'money', 'suit', 'truck', 'one on right', 'canoe', 'tomato', 'on refrigerator', 'candy canes', '1:55', 'relaxing', 's early st', 'teddy', 'ipod and iphone', 'hot plate', 'landing', 'suitcases', 'ice cream container', 'glasses', 'plastic', 'mom', 'cartoons', 'grind', 'ss', 'eligible', 'heaver bros ltd', 'theater', 'slacks', 'dresser', 'creepetz', 'kiwi', 'man in blue and yellow', 'ginger', 'sheep and dogs', 'nelsons', 'balance', 'korean', '12:05', 'taller', 'raspberries', 'chihuahua', 'straw', 'rocks', 'turkey', 'printer', '329', 'ponytail', 'tail', '53', 'summer', 'elliott', 'days', 'for photo', 'cats', 'hammer', 'mario', 'christian flores', 'pigeons', 'plates', 'wavy', 'playing frisbee', 'east', 'classroom', 'fixing their skis', 'dalmatian', 'china', 'mountain dew', 'in field', 'sydney', 'closer', 'nike', 'starbucks', 'sb', 'orange and white', 'kimberly', 'collie', 'jacket', 'referee', 'legos', 'tie dye', 'listening', 'bowls', 'holding camera', 'parking', 'pig', 'gala', 'police', 'for fun', 'sunexpress', 'natural habitat', 'teddy bear maker', 'smiley face', 'slippery when wet', 'pocket', 'mushrooms', 'beard', 'roller coaster', \"man's\", 'clock', 'historycom', '3834', 'chicken', 'hot', 'shutters and scooter', \"in man's hand\", 'smiling', 'as advertised', 'vanilla', 'mutt', 'brakes', 'legs are evident', 'skate', 'tattoo', 'lion', 'willow', '64', 'tile', 'christian', 'pink and green', 'on ground', 'enter', 'lanyard', 'brushing hair', 'granite', 'lemons', 'indoors', 'camo', 'purple', 'cheddar', 'man and truck', '22-296', 'aliens', 'plastic wrap', 'stripe', 'red', 'some', 'bull', 'stars', 'ski jumper', 'lamps', 'ring road', 'below picture', 'come', 'cupboard', 'no curtain', 'f', 'on wall', 'bell', 'planes', 'wednesday', 'cosmo', 'basil', 'sky', 'xbox', 'shaking hands', 'hood', 'poodle', 'lots', 'lake', 'mirror', 'rileys', 'cold', 'on desk', 'at donut shop', 'triangle', 'cloth', 'steel', 'peace', 'german shepherd', 'ground', 'tie', 'vehicle model', '16', '27 cents', 'ivory', 'stuffed animals', 'studying', 'algae', \"it doesn't\", 'snowsuit', 'mugs', '3076', 'full', 'wii remotes', 'on grass', 'hello', 'wearing mask', 'skateboarding', 'round', 'farmer', 'soldier', 'triscuit', 'ride horses', 'wrinkled', 'yard', 'christmas', 'wetsuits', 'old town street', 'briefcase', 'broccoli', 'white with black stripes', 'cheap', 'leaves', 'wolf', 'to fly somewhere', 'dress', 'comcast', 'skatepark', 'green and yellow', 'st germain', 'oasis', 'attention double sens', 'sneakers', 'picture', 'left', 'main course', 'model', 'african american', 'private', 'in sand', 'bicycles', 'green and blue', 'rtbf', 'vancouver', 'cow', 'chest', 'little tikes', 'kicking ball', 'black sheep', 'hyundai presbyterian church', 'atp', 't shirt', '60', 'stripes', 'cutting grapes', 'oil lamps', 'toilet', 'future of ideas', 'helmets', 'ring', 'streetlight', 'stairway', 'desert', 'fall', 'x64', 'peeling', 'not possible', 'to say it all', 'coffee', 'kha', '11:30', 'main', 'room', 'night time', 'web page', 'choppy', 'opaque', 'railing', 'indicates table number', 'man in front', 'chips', 'bucket', 'reds', 'ham', 'white', 'painting', 'meat', 'statue', '431', 'mold', 'for food', '49', 'n', 'wedding day', 'analog', 'lamp', 'document', \"they're not\", 'pork', 'morning', 'propeller', 'woodstock', 'getting food', 'teddy bears', '87', 'tank top', 'to stop', '10 minutes', 'hair', '11:18', 'lighthouse', 'diner', 'green facts', 'stunt', 'strawberry banana', '2005', 'helping', 'scooter', 'llama', 'to serve', 'spoon', 'small', 'tongue', 'electric company', 'german', 'barn', 'nurse', 'merton street', 'by trees', 'girl', 'country', 'poor', 'skateboards', '143', 'custom', 'beige', 'black and yellow', 'sandals', 'stair rail', 'serve', 'ear', 'roman', 'riding', 'clare dragoon', 'center', 'sausage', 'kitchen', \"i don't know\", 'carole nash', 'window sill', 'old', 'arrow', 'computer', 'pitcher', 'flushing', 'in water', '64 and 41', 'headphones', 'toward', 'potato', 'dusk', '6/8/2003', 'carpet', 'portable', 'moving', 'bus stand', 'playing wii', '6050', 'website', 'to make salad', 'kensington square', '19', 'usopenorg', 'zebra', 'ketchup', 'black & decker', 'adidas', 'e braddock rd', 'narrow', 'closed', 'fountain', 'bag', 'baby', 'taking off', 'afternoon', 'lost', \"he isn't\", 'by plane', 'white and black', 'in mud', 'javelin', 'wheels', 'bird', 'racket', 'blue and yellow', '9:05', 'santa hat', 'bottom tray', 'tower', '12:25', 'iron eagle', 'beulah & stanyan', 'omelet', 'cedars assist', 'kenmore', 'traveling', 'phone', 'gower st', 'siamese', 'women', 'plants', 'kites', '11:00', 'wild', 'gym', 'bun', 'best friends', 'vent', 'milk', 'stainless steel', 'piccadilly gardens', 'raise plow', 'indian', '444 007', 'forward', 'on counter', 'pyramids', 'night', '60016', 'jets', 'torso', 'trail', '81a', 'gravel', 'hebrew', 'no shoes', '13', 'real', \"it's daytime\", 'shock', 'surfboards', 'barber shop', 'tennis player', 'roundabout', 'dugout', 'feeder', '9:45', 'amish', 'to get to other side', 'on pizza', 'cd', 'to hit ball', 'talking', 'porcelain', 'harley davidson', 'trees', 'walk dog', 'low', 'sign pen', 'teens', 'pink, green and yellow', 'crawford', 'beams', 'she is wearing long sleeves', 'touching', 'parrots', 'band', 'batting', 'pants', 'sippy cup', 'salt', 'ak', 'dogs', 'barnet church', 'kayaking', '328', 'hbo', 'iphone', 'on dish', 'multi', 'fedora', 'sprite', '420', 'power lines', 'stones', 'red/green', 'abbetved', 'hot pink', 'airport', 'factory', 'bug', 'no birds', 'boat', 'ties', 'making fist', 'head', 'mittens', 'pockets', 'apron', 'rawlings', 'looking out window', 'potatoes', 'boxer', '127', 'to play', 'checkered', 'departing', '5:18', 'carrots', 'cabbage', 'rainbow', 'or best', 'packing', 'leg', 'blanket', 'cutting cake', 'short', '0341', 'carrot', 'jeans', 'heart', 'camera', 'happy birthday timothy', 'kelly', 'electric', 'singles', 'flapping wings', 'dell', 'serving', 'building', 'river', 'ashes', 'george washington university', 'john kaminski', 'un', 'colgate', 'tracker', 'boston', 'cabs', 'nuts', '45110', 'emirates', \"modell's\", 'hope', 'not', 'overweight', 'paisley', 'plantains', 'fez', 'there is no woman', 'day time', 'cherries', 'tying his tie', 'travel items', 'coke', 'speedboat', 'uc irvine', 'rambutan', '5 years', 'watching tv', 'peas', 'floral', 'play tennis', 'unmade', 'snowboarder', 'red sox', 'festival', '10:10', 'crates', 'buttery', 'diamonds', 'rural', 'game to start', 'fire truck', 'laying', 'sir matt busby way', 'cakes', 'green and black', 'plucking eyebrows', 'in case', 'crosswalk', 'standing on toilet', 'lemon', 'green', 'audrey hepburn', 'curly', 'braided', '50', 'cleaning', 'data', '788', 'sports', 'warning', 'plant', 'on her hips', 'jersey', 'quilt', 'riding bike', 'hungry', 'watching video', 'bird bath', 'peterbilt', 'for cat', 'dishwasher', 'fly', 'glaze', 'skiing', 'orange and black', '17', 'playground', '10', 'wipeout', 'grape', 'thanksgiving', 'jack daniels', 'recently', 'brown and white', 'amtrak', 'gown', 'birds', 'yellow and green', 'control', 'loop', 'white, black', '785', 'terrier', 'soccer ball', 'bus station', 'gun cleaning', 'queen', '10:30', 'tennis racket', 'red and brown', 'm', 'fairfax', 'passenger', 'ski poles', 'star', 'fish', 'kicked it up', 'tall', \"there aren't\", 'celery', 'walking', 'nastro azzurro', 'hose', 'residential', 'brushing', 'ducks swim', 'bike', 'poinsettia', 'air canada', 'grant', 'male', 'no sign', 'face', 'stop', '2 adult males', 'used', 'sunlight', 'post no bills', 'in motion', 'hilton', 'lenovo', 'red and black', '4 months', 'almonds', 'in air', 'street signs', 'all', 'canoes', 'book', '3:42', 'fries', 'trained', 'mail', 'astroturf', 'rackets', 'toilet paper only', 'papers', 'nighttime', 'clean', 'worn', 'marlboro', '11:10', 'longboard', '45', 'branch', 'juice', 'light', '57', 'brinley', '08/14/2013', 'frisbee golf', 'frosty', 'glass', 'to protect it', 'jet', 'phang nga', 'donuts', \"men's\", 'return', 'triangles', 'plate', 'watching game', 'baseball', 'film and razors', 'crutch', 'supreme', 'cheesecake', 'circle', 'hitting ball', 'toyota', 'thumb', '3 hour parking', 'blue and green', 'headband', 'tulip', 'pitching', 'chalk', 'shetland', 'living room', '5 feet', 'playing game', 'next to bananas', 'crow', 'neither', '10 feet', 'rotten part', 'red and yellow', 'broccoli eggplant lasagna', 'empty', 'cardinals', '30-47', '2013', 'cat and mouse', 'clothes', 'color', '15:48', 'cake server', 'cadillac', 'boy', 'broccoli and fish', 'little', 'tennis rackets', 'club members', 'bethnal green', 'talking on phone', 'counter', 'frog', 'golden', 'silk', 'battery', 'bridge', 'apples', 'barclays', 'seansadventureinflavortowncom', 'not raining', '118', 'second from right', 'beauty salon', 'sandwich', 'entree', 'on umbrella', 'magazines', '6', 'curb', 'singapore airlines', 'no bow', 'holding them out', 'pontoon', 'shopping center', 'united states', 'aloe', 'no chipotle', 'cleveland', 'flying kite', 'knee pads', 'on laptop', 'skier', 'knife and fork', 'lta', 'england', 'vibration', 'tines', 'listerine', 'windshield', 'arriva bus', 'vegetarian', 'street sign', 'gray and blue', 'color of face', 'above sink', 'blue white and yellow', '11 st se and 9 ave se', 'windows', 'sejikiubben', 'urban', 'moist', 'glass cabinet', 'athlete', 'run', 'mountains', 'travel company', 'museum', 'tire', 'black and white', 'five star', 'australia', 'zipper', 'green and blue striped', 'blur', 'sailboat', 'gold', 'slightly', 'qefd', 'deep dish', 'in batters hand', 'burlap', 'angels', 'steak and fries', 'ollie', 'pulled back', '7097', 'sierra nevada', 'dhl', 'white, red, brown', 'sheetrock', 'to clean', 'boogie board', 'pen knife', 'from front', 'drywall', 'stm', 'female impersonators', 'tucked', '3308', 'slow', '2', 'silver', '1 mile', 'no giraffe', 'sitting on surfboard', '851', 'friends', 'soup', 'expert', 'deer', 'none', '20', 'rear', 'john', '308', 'tennis', 'california', 'robins', 'background', 'brown', 'man on left', '10 years', 'in basket', 'trip hazard', 'vw', 'onion rings', 'united', 'backhand', '63', 'nothing', 'windsurfing', 'kettle', 'sedan', 'standing', 'in plane', 'wicker', 'apple and orange', 'san francisco', 'lens', 'around girl', 'identification', 'silver, red, blue', 'bikes', 'english', 'san diego', 'winter', 'swimming', 'tiles', 'mammal', 'brown and tan', 'antique', 'propellers', '0', 'shoes', 'jal', 'here', 'bob', 'hotel samara', 'painted', 'ceramic', 'dirty', 'unknown', 'later', 'brushing teeth', 'in his pocket', 'rectangle', 'sock', 'ski gear', 'flower', 'monitor', 'overalls', 'bald man', 'wine bottle', 'road runner sports', 'tortilla', 'to catch ball', 'clip', 'eggs', 'drill', 'town', 'pink', 'parking lot', 'bird feeder', 'beans', 'grass', 'bunk', 'microwave', 'cuv186c', 'rugby', 'party', 'florida', 'lexus', 'window', 'green and orange', 'surfer', 'walking dog', 'purse', 'drink', 'wakeboard', 'cooking', 'blue, silver, purple', 'a', 'surf shop', 'on couch', 'party hats', 'bottom middle', 'banana split', 'clouds', 'vest', 'cream and red', 'natural', 'furniture and cardboard boxes', 'motorcycles', 'coca cola', 'racing', 'army doctors', 'sprinkler', 'prom', 'on pole', 'relish', 'cap', 'social media', 'oil', 'yarn', 'shorter', 'suspension', 'heads', 'above bus', 'ski resort', 'hundreds', 'stardust', 'garbage', 'tools', 'its empty', 'on', 'rolling', 'horizontal', 'fan', '701', \"you can't\", 'chairs', 'ldh', 'mattress', 'mosaic', 'teal', 'dandelion', 'france', 'above toilet', 'africa', 'shirts', '28', 'roses', 'wood', 'protection', 'school', 'motocross', 'box', 'dining', '120', 'on dirt', 'male and female', '15 feet', 'robin', 'bottle', 'stars and stripes', 'motorcycle', 'wii controller', 'corridor', 'cornrows', 'for electricity', 'fog', 'pencil', 'middle 1', 'water bottle', 'tony minghine', 'cones', 'getting haircut', 'feeding giraffes', 'sauerkraut', 'shades', 'westerville police division', 'klm', 'cupcakes', 'van', 'heineken bier', 'black and tan', 'city', 'in bowl', 'to shop', 'kickstand', 'russian', 'to right of plate', 'rocky mountains', 'boots', 'michael', 'tarp', 'floor', 'napkin', 'large', 'seat number', 'pews', 'umpire', 'on land', 'tic tacs', 'on top of gnome head', 'cleaning materials, paper plates, cooler, potato chips', 'elephant and bull', 'soda', 'broken', 'no plane', 'ketchup and mustard', 'burton', 'yellow', 'seaport cafe', 'blurred', 'cushion', 'home', 'man', 'eating animals', 'usa', 'black', 'chocolate lab', 'china cabinets', 'miami', 'skis', 'oven mitt', 'tops', 'for airport', 'hug', 'bed', 'red bull', 'no parking', 'poles', 'hulk', 'pigeon', 'spring', 'american flag', \"cooper's\", 'couch', 'december', 'belt', 'there are no flowers', 'lunch', 'baseball cap', 'sweatpants', 'sidewalk', 'carrying frisbee', 'traffic lights', '200', 'blue and pink', 'sliders', 'stereo', 'bottles', 'hat', 'no home', 'side of road', 'chopsticks', 'red, white, blue', 'new', \"can't\", 'behind giraffe', 'colored', 'laptops', 'lg', 'tate modern', 'flowers', '27', 'jimmy', 'off', 'giraffes', '74', 'forest', 'crochet', 'day', 'champagne', 'on display', '1st', 'noon', 'sheep herder', 'bracelet', 'hands', '934', 'rope', 'wall', 'poster', '30629', 'windmill', 'watching', 'any of them', '2:50', 'shrimp', 'fast', 'bank of america', 'dinner', '80', 'radio', 'basket', 'goat', 'motor', 'cone', 'water', 'air', 'flying kites', 'hunting', 'dirt', 'raspberry', '88', 'official gear is officially here', 'franz venhaus', 'very tall', 'riding horse', 'baghdad', 'shorts', 'sign', 'taking photos', '22', 'angry', 'oak', \"it's beach\", 'one way', 'rand mcnally', 'flying', 'trucks', 'keyboard', 'washbourne', 'behind table', '11:50', 'feeding', 'work', 'clear', 'oven', 'enemies', 'dodgers', 'yelling', 'soup and sandwich', 'in box', 'sleep', 'food', 'brick oven', 'merrell', 'never', 'jose cuervo', 'fire station', 'married', 'olive garden', 'ducks', 'towards', 'remote control', 'paris', 'fire', 'person', 'saucer', 'tardis', 'both', 'digital art', 'bird seed', 'top left', 'soccer', 'j-144', 'nintendo', 'often', 'down', 'square', 'christmas tree', 'ipod', 'princess', 'sweater', \"joey's place\", 'above fireplace', 'below', 'whirlpool', 'american', 'collar', 'adults', 'green and white', 'playing with bird', '100 feet', 'tangerine', 'daytime', 'strike', '2 feet', 'umbrellas', 'chariot', '8', 'e 40 289', 'photographer', 'tracks', 'anchors', 'romney', 'garage', 'trash can', 'pez', 'p', 'meditating', '434-760-2506', 'top right', 'sprint', 'kickflip', 'black, white, gold', 'bidet', 'pay money', 'j', 'stove', '3 feet', 'doorknob', 'soap', 'signs', 'banjo', 'over', 'salad', 'heels', 'avocado', 'passes', 'red and white', 'posing', 'long', 'purple pink blue orange yellow black', 'kearny', 'bow', 'ramp', 'medium', 'blue and red', 'dragons', 'slumber party', 'float', 'hair dryer', 'snowboard', '2 towels', 'electronic', 'juan n only', 'cane', '023236', 'toward camera', 'radiator', 'to cook', '9', 'beach', 'fishing', 'escalator', '0118 948 1000', 'collars', 'pasta', 'no', 'paper towels', 'train', 'buckling snowboards', 'snowboarding', 'award', 'marines', 'soap dispenser', 'hydrant', 'kia', 'cup and mouse', '1a', 'goggles', 'kingfisher', 'green and silver', 'daisy', 'bat', 'several', 'tarmac', 'westjet', 'crocheted', 'santa', 'spectators', 'harley', 'butternut', '1935', 'india', 'overnight', 'library', '6:20', 'russia', \"twenty's plenty\", 'deck', 'on shelf', 'italian', 'right one', 'swinging bat', 'cilantro', 'neck and stomach', 'car show', '500', '4:05', 'car', 'cards', 'c', 'hit ball', 'television', 'waves', 'tennis game', 'thumbs up', 'orange', 'hot dog', 'desk assistants', 'confusion', 'genstyle', 'trunks', 'prime minister of myanmar', 'tractor', 'castle', 'frying', 'stairs', 'art', 'rolled them', 'great houses of britain', '666', 'computer tower', 'tws', 'mad about something', 'viking', 'preference', 'subway', 'its advertising object', 'coins', 'passengers', 'los angeles', 'elgin county archives', 'pool', 'outward', 'vase', 'best coast', 'controllers', 'walking horse', 'cantaloupe', 'japan', 'green tan', 'wacom', 'sprinkles', 'pepper', 'carpeted', 'canada donut', 'okra', 'onions', 'sale', 'steep', 'gas', \"it's autumn\", '228th', 'shin guards', 'shelves', 'truck and bus', 'shirt', 'fighting', '1:1', 'kingstown harbour', 'lift', 'candid', 'courthouse', 'comfort', 'bananas', 'motion', 'ornament', 'texas a&m', 'bakery', 'fire hydrant', 'evening', 'helicopter', 'dancing', 'horse and buggy', 'herding', 'cars', 'l', 'tiaras', 'concert', 'lo', 'cooler', 'both men', 'far right', 'sunset', 'train station', 'cows', 'toys', 'dr pepper', 'next train', 'somewhere', 'paddle', 'shampoo', 'picnic', 'in front of couch', 'green and brown', 'blocks', 'home base', 'sunny', 'cookies', 'bulova', 'on skis', 'away', 'playing', '1872', 'under cat', 'camouflage', 'love', 'airplane', 'solid', 'clay', 'tv', 'mountain', '21', 'twin city', '58', 'boxes', 'lorifice', 'sun', 'canoeing', 'across street', 'can', '23', 'skate park', '1498', 'lasagna', 'soup spoon', 'suv', 'hush potato', 'man is squinting', 'millions', 'pottery', 'umbrella', 'no trick', 'hotel', 'fashion', 'bacon', 'vegetables', 'not waiting for bus', 'hot dogs', 'tree', '2:14', 'sleeping', 'wall hanging', 'argo', 'seat', 'playing tennis', '24', '100 gallons', 'joy', 'wetsuit', 'blinds', 'stroller', 'pacific southwest', 'horses', '8 hours', 'levi', 'stadium', 'n6594q', 'screen', 'e-on', 'iris', 'boy scouts', 'on table', 'spiderman', '5', 'birthday and graduation', 'graffiti', '10:05', 'tan', 'on plate', 'cubs', 'wave', 'foot', 'wii', 'distance', 'washington', 'hello kitty', '90 degrees', 'aggies', 'to shore', 'on truck', 'shirt and jeans', 'parking meter', 'warmth', 'to cut', 'baseball bat', 'chain link', 'in front of car', 'pack', '6861', '12 feet', 'yellow and blue', 'plane', 'batter', '4 feet', 'confused', 'rowing', 'asphalt', 'bamboo', 'peeing', 'pearls', 'pacific coastal', '7', 'good', 'diet coke', 'tent', 'new york', 'right', '152', 'krispy kreme', 'hole punch, scissors, mechanical pencil', 'food shark dining car', 'boating', 'yoga', 'to keep people out', 'highway', 'transportation', 'scarf', 'olives', 'short shorts', 'butter', 'cover', '18', 'tablecloth', '1:00', 'sea', 'fork', 'cucumber', 'controller', '6:27', 'bagel', 'princess tours', 'opponent', 'downtown', 'fireplace', 'eldest', '10:33', 'trunk', 'conveyor', 'skyfall', 'tea set', 'camping', '2nd', 'wine', 'flintstone', 'catcher', 'lot', 'bulldog', '4:18', 'z', 'mad', 'on bridge', 'snow', 'donut', 'magnet', 'beer', 'orioles and toronto', 'freight', 'rubber', \"you're walking through poetry\", 'bas sekolah', 'benefit joey d williams', 'navy', 'books', 'candy', 'waverley', '35', 'on floor', 'pizza', 'no wind', 'ownership', '1.10', 'scissors', 'people', 'cup', 'public', 'delicious', 'late show', 'bread and tater tots', 'migrating', 'rails', 'towing', 'downhill', 'prisoners', 'fabric', 'desk', 'floor lamp', 'moreland fruit farm', 'sony', 'costume', 'lush and green', 'sword', 'trailer', '20 ft', 'nowhere', 'drinking', 'butterfly', 'cake', 'appliances', 'frito lay', 'corn', 'bags', 'dash', 'do not enter', 'track', 'kona', 'blue and white', 'his outfit', 'in focus', 'fluorescent', 'miami eagles', 'yellow and purple', 'license plate', 'convention', 'transp center', 'grapes', 'on left', 'palm', 'giraffe', 'fair', 'above stove', '40', 'wwii', 'probot', 'octagon', 'asian', 'essex park', 'emergency', 'tricks', 'brown and yellow', 'pickle', 'hp', 'bus lane', 'up', 'fedex', 'on plane', 'younger', 'scrabble', 'phones', 'pictures', 'to see', 'middle', 'ball', 'white and blue', 'greens', 'corner', 'rose', 'wild bear', 'asche', 'paddle boat', 'elephants', 'sunflowers', 'apple', 'bachelorette', '10:42', 'shadow', 'french fries', 'pizza and onion rings', 'mochi', 'grill', 'wmdt', 'maple', 'us air force', 'buses', 'different companies', 'straight', 'writing', 'grocery', 'gift shop', 'nobody', 'mulleys motorways', 'stone', 'office', 'behind clock', 'washington dc', 'deep', 'enclosure', 'ocean', 'young', '14', '100', 'on face', 'pine', 'steeple', 'yellow, green, blue, red', 'sewing', 'south', 'wallet', 'around face', 'looking at screen', 'hanging', 'running', 'playing baseball', 'tokyo', 'telling time', 'biking', 'calm', 'years', 'random', 'sand', 'second floor', 'reading', 'pepperoni', 'plains', 'owls', 'sandwiches', 'behind catcher', 'spider', 'top', 'cracker', 'hand', 'lettuce', 'visor', '3:07', 'ladybug', 'london', 'waving', 'pole', 'directions', 'free', 'glover park', 'young adult', 'college pt', 'spots', 'mushrooms and spinach', 'bottom', 'sheep', 'body', 'marina', '60010', 'strawberries', 'tartar sauce', 'barrette', 'dump truck', '25', 'gray and red', 'road', 'converse', 'attached to plane', 'playing video games', 'clark', '34', 'surfboard', 'mac', 'blender', 'surfing', 'dog and sheep', 'roman numerals', 'rust', 'pan', 'stool', 'feta', 'drum', 'wind', 'sitting', 'pee', 'e 82 st', 'shelf', 'storm', 'ceiling', 'baker', 'remote', 'cruiser', 'leather', 'peace way', 'necklace', 'clock tower', 'ruins', 'all of them', 'stuffed animal', 'telephone', 'read', 'peacock', '12:27', 'chevrolet', 'cookie sheet', 'egg', '6:00', 'echo', 'offense', 'blonde', 'metal', 'only', 'bus', 'home depot', 'above', 'beanie', 'outside', 'normal size', 'sunglasses', 'protein', 'cannabis defense coalition', 'kite', '2:15', 'messy', 'panhandling', 'motel', 'no number', 'leith', 'enfield', '1 on right', 'red tie', 'descending', 'winnie pooh', 'dead grass', 'dog', '47', 'wwwltaorguk', 'grits', 'military', 'red white and blue', \"it's fast\", 'tub', 'plums', 'jdate', 'pillow', 'flag', '50 feet', 'very high', 'farm', 'alvin and chipmunks', 'luggage', 'cox', 'mall', 'gray white', '8:32', 'towel', 'light fixtures', 'electricity', 'no tank', 'tulips', 'stands', 'pipe', 'breakfast', 'diary of wimpy kid', '3 hour limit', 'back', 'casserole', 'ski', 'sink', 'red velvet', 'missouri', 'gray', 'thrown', 'church', 'reflection', 'toy', 'mta metro-north', 'not likely', 'lights', 'lava', 'safe', 'woven', 'man on right', 'well', \"user's guide\", 'student', 'zoo', 'horse riders', 'information', 'bear', 'banana', 'north face', 'police car', 'it is cat', 'children', '55', 'casual', 'cafe', 'canada', 'prison', 'wrigley', 'french', 'no boy', 'next to car', 'emmi', 'looking', 'very', \"valentine's day\", 'chopping carrots', 'bright pearl', 'wii remote', 'suitcase', 'water skiing', 'polka dot', '11:25', 'lo mein', 'bandana', 'leonidas smith 1866 2013', 'tissues', 'automatically', 'fila', 'fans', 'apartment', 'glove', 'he has trophy', 'conductor', 'helmet', 'backpack', 'elephant riding', 'shut', 'beagle', 'cargo', 'ketchup and onions', 'woman and cat', 'no 1', 'green and red', 'adult', 'wilson', 'plug it in', 'embrey exposures', 'mustard', '12:55', 'rooster', 'hay', 'birthday', 'warm', 'baseball field', 'tray', 'fridge', 'chocolate', '266', 'peanut butter and jelly', 'arm', 'u haul', 'tie knot', 'woman', 'decoration', 'sepia', 'bulls', 'rice', 'xper', 'modern', 'team color', 'triumph', 'skull and crossbones', 'pizza cutter', 'cross street', 'glass doors', 'plaster', 'scrunchie', 'no shorts', 'shower curtain', 'jackets', 'restaurant', 'swing', 'volvo', 'vehicles', 'ordering food', 'field', 'storage', 'taking picture', 'end bird', 'quartz', 'federal', 'picking up food', 'matt damon', \"can't you see it's green?\", '2008', 'flan', 'first aid', 'brown bear', 'many', 'vertical', 'shop', 'doughnuts', 'berries', 'intersection ahead', 'continental', 'domestic', 'overcast', 'behind', 'bombardier', 'carriage', 'frisbee', 'pepsi', 'growing leaves', 'ski pole', 'eyes', 'upholstery', 'fiber', 'dip', 'sisters', '10:20', 'flour', \"he's not\", 'no stopping', 'get soap', 'resting', '140', 'watch', 'music', 'mug', 'bathroom', 'busaras', 'next to horse', 'hotel room', 'pick up', 'saddles', 'friend', 'rain', 'dry', 'pedestrian', 'jar', 'masnedogade', 'pacifier', 'tripod', 'to wear', 'oranges', 'serviced', 'black and blue', 'blueberries', 'cargolux', 'bread', 'higher', 'waterpark', '2 way', 'blood', 'hats', 'exit', 'feeding birds', 'doing trick', 'horse', 'joshua', 'shadows'}\n",
            "Number of training classes: 2505\n",
            "Number of validation samples: 2658\n",
            "Number of test samples: 2579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "dU2IrxY-rXTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transformations\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "#image_transforms = transforms.Compose(\n",
        "#    [transforms.Resize((224, 224)), transforms.ToTensor(), normalize]\n",
        "#)\n",
        "eval_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "image_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Fh2GPpxzrYWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset and dataloader"
      ],
      "metadata": {
        "id": "nbmuKHKWrZcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VQADataset(Dataset):\n",
        "    def __init__(self, images, questions, answers, transform=None):\n",
        "        self.images = images\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        question = torch.tensor(self.questions[idx], dtype=torch.long)\n",
        "        answer = torch.tensor(self.answers[idx], dtype=torch.long)\n",
        "        return image, question, answer\n",
        "\n",
        "train_dataset = VQADataset(\n",
        "    train_selected_images,\n",
        "    train_padded_questions,\n",
        "    train_answer_classes,\n",
        "    transform=image_transforms,\n",
        ")\n",
        "\n",
        "val_dataset = VQADataset(\n",
        "    val_filtered_images,\n",
        "    val_padded_questions,\n",
        "    val_answer_classes,\n",
        "    transform=eval_transforms,\n",
        ")\n",
        "\n",
        "test_dataset = VQADataset(\n",
        "    test_filtered_images,\n",
        "    test_padded_questions,\n",
        "    test_answer_classes,\n",
        "    transform=eval_transforms,\n",
        ")\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "test_data_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "W9oFSUpOrbuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model architecture"
      ],
      "metadata": {
        "id": "U-PUu4tOrecO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, image_dim, text_dim, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.image_att = nn.Linear(image_dim, hidden_dim)\n",
        "        self.text_att = nn.Linear(text_dim, hidden_dim)\n",
        "        self.final_att = nn.Linear(hidden_dim, 1)\n",
        "        self.bn_image = nn.BatchNorm1d(hidden_dim)  # BatchNorm for image features\n",
        "        self.bn_text = nn.BatchNorm1d(hidden_dim)   # BatchNorm for text features\n",
        "        self.dropout = nn.Dropout(p=0.2)  # Dropout after attention layer\n",
        "\n",
        "    def forward(self, image_feats, text_feats):\n",
        "        img_att = self.image_att(image_feats)  # [batch_size, num_pixels, hidden_dim]\n",
        "        txt_att = self.text_att(text_feats)    # [batch_size, hidden_dim]\n",
        "        combined_att = F.relu(img_att + txt_att.unsqueeze(1))\n",
        "        #combined_att = self.dropout(combined_att)\n",
        "        att_scores = F.softmax(self.final_att(combined_att), dim=1)  # [batch_size, num_pixels, 1]\n",
        "        weighted_feats = (image_feats * att_scores).sum(dim=1)  # [batch_size, image_dim]\n",
        "        return weighted_feats\n",
        "\n",
        "class VQAModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_answers, image_feature_dim):\n",
        "        super(VQAModel, self).__init__()\n",
        "        # Initialize Faster R-CNN model\n",
        "        fasterrcnn = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "        self.frcnn_backbone = fasterrcnn.backbone.body\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.attention = Attention(image_dim=image_feature_dim, text_dim=hidden_size, hidden_dim=512)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
        "        self.dropout_lstm = nn.Dropout(p=0.5)  # Dropout after LSTM\n",
        "\n",
        "        # Classifier\n",
        "        self.fc1 = nn.Linear(hidden_size + image_feature_dim, 512)\n",
        "        self.dropout_fc1 = nn.Dropout(p=0.5)  # Additional dropout before first fully connected layer\n",
        "        self.fc2 = nn.Linear(512, num_answers)\n",
        "\n",
        "    def forward(self, images, questions):\n",
        "        # Image features\n",
        "        features = self.frcnn_backbone(images)\n",
        "        last_layer_key = list(features.keys())[-1]\n",
        "        img_features = features[last_layer_key]\n",
        "        img_features = F.adaptive_avg_pool2d(img_features, (1, 1))\n",
        "        img_features = img_features.view(img_features.size(0), -1)\n",
        "\n",
        "        # Process text\n",
        "        embedded = self.embedding(questions)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        lstm_out = self.dropout_lstm(lstm_out)\n",
        "        question_repr = lstm_out[:, -1]\n",
        "        question_repr = self.dropout_lstm(question_repr)  # Apply dropout after LSTM\n",
        "\n",
        "        # Attention\n",
        "        attended_img_feats = self.attention(img_features, question_repr)\n",
        "\n",
        "        # Classifier\n",
        "        combined = torch.cat([attended_img_feats, question_repr], dim=1)\n",
        "        x = self.fc1(combined)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout_fc1(x)  # Apply dropout before first fully connected layer\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Model initialization\n",
        "VQA_NET = VQAModel(\n",
        "    vocab_size=len(tokenizer.word_index) + 1,\n",
        "    embed_size=256,\n",
        "    hidden_size=512,\n",
        "    num_answers=len(train_classes),\n",
        "    image_feature_dim=2048\n",
        ")"
      ],
      "metadata": {
        "id": "xhYsoVusrf4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8728c218-9140-4496-fef5-92834150cf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:00<00:00, 175MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation"
      ],
      "metadata": {
        "id": "VqBKGjw-rhXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "question_types = ['what', 'where', 'how many', 'which', 'is there', 'does the', 'are there']\n",
        "\n",
        "def identify_question_type(question):\n",
        "    for q_type in question_types:\n",
        "        if question.lower().startswith(q_type):\n",
        "            return q_type\n",
        "    return 'other'\n",
        "\n",
        "# Function for Gradient Clipping\n",
        "def clip_gradients(model, clip_value):\n",
        "    parameters = [p for p in model.parameters() if p.grad is not None]\n",
        "    for p in parameters:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "\n",
        "# Function for Learning Rate Decay\n",
        "def adjust_learning_rate(optimizer, epoch, decay_rate, initial_lr):\n",
        "    lr = initial_lr * (decay_rate ** epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "    recall = recall_score(true_labels, predicted_labels, average=\"weighted\", labels=np.unique(predicted_labels))\n",
        "    f1 = f1_score(true_labels, predicted_labels, average=\"weighted\", labels=np.unique(predicted_labels))\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Function to convert tensor to image\n",
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor.cpu().clone()\n",
        "    tensor = tensor.squeeze(0)\n",
        "    tensor = unnormalize(tensor)\n",
        "    tensor = tensor.numpy().transpose(1, 2, 0)\n",
        "    tensor = np.clip(tensor, 0, 1)\n",
        "    return tensor\n",
        "\n",
        "# Unnormalize function\n",
        "def unnormalize(tensor):\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)    # unnormalize\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "RKIm9IRvrhA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single split training/validation"
      ],
      "metadata": {
        "id": "2r3CVPYQrkfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import sklearn.exceptions\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import csv\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
        "\n",
        "# Training Parameters\n",
        "EPOCHS = 1000\n",
        "LEARNING_RATE = 0.001\n",
        "DECAY_FACTOR = 0.999\n",
        "WEIGHT_DECAY = 0.001\n",
        "CRITERION = nn.CrossEntropyLoss()\n",
        "OPTIMIZER = optim.Adam(VQA_NET.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "VQA_NET.to(device)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "wait = 0\n",
        "\n",
        "# Initialize storage for predictions and labels by category\n",
        "category_predictions = {q_type: [] for q_type in question_types}\n",
        "category_true_labels = {q_type: [] for q_type in question_types}\n",
        "\n",
        "for epoch in range(1,EPOCHS+1):\n",
        "\n",
        "    # Training phase\n",
        "    VQA_NET.train()\n",
        "    adjust_learning_rate(OPTIMIZER, epoch, DECAY_FACTOR, LEARNING_RATE)\n",
        "    total_loss = 0.0\n",
        "    for i, (images, questions, labels) in enumerate(train_data_loader):\n",
        "        images, questions, labels = images.to(device), questions.to(device), labels.to(device)\n",
        "        OPTIMIZER.zero_grad()\n",
        "        outputs = VQA_NET(images, questions)\n",
        "        loss = CRITERION(outputs, labels)\n",
        "        loss.backward()\n",
        "        #clip_gradients(VQA_NET, 10)  # Gradient clipping\n",
        "        OPTIMIZER.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Avg train loss\n",
        "    avg_loss = total_loss / len(train_data_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    VQA_NET.eval()\n",
        "\n",
        "    all_pred_labels = []\n",
        "    all_true_labels = []\n",
        "    total_val_loss = 0.0\n",
        "    correct_answers = 0\n",
        "    total_answers = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, questions, labels in val_data_loader:\n",
        "            images, questions, labels = images.to(device), questions.to(device), labels.to(device)\n",
        "            outputs = VQA_NET(images, questions)\n",
        "            loss = CRITERION(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_answers += (predicted == labels).sum().item()\n",
        "            total_answers += labels.size(0)\n",
        "            _, predicted_labels = torch.max(outputs, dim=1)\n",
        "            all_pred_labels.extend(predicted_labels.cpu().numpy())\n",
        "            all_true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Evaluate validation performance after each epoch\n",
        "    current_val_loss = total_val_loss\n",
        "    if current_val_loss < best_val_loss:\n",
        "        best_val_loss = current_val_loss\n",
        "        best_epoch = epoch\n",
        "        wait = 0  # Reset wait time if there's an improvement\n",
        "        # Save the model checkpoint if this is the best model so far\n",
        "        torch.save(VQA_NET.state_dict(), f'/content/drive/MyDrive/Deep_learning/model_states/new_model_rcnn{epoch}.pth')\n",
        "    else:\n",
        "        wait += 1  # Increment wait time if no improvement\n",
        "\n",
        "    # Scheduler update\n",
        "    SCHEDULER.step(current_val_loss)\n",
        "\n",
        "    # Compute and display metrics\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(all_true_labels, all_pred_labels)\n",
        "    print(f\"Epoch [{epoch}/{EPOCHS}] | Training Loss: {avg_loss:.4f}, Validation Loss: {current_val_loss:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Write results to file for analysis later\n",
        "    with open('/content/drive/MyDrive/Deep_learning/epoch_statistics_baseline.csv', 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([epoch, avg_loss, current_val_loss, accuracy, precision, recall, f1])\n",
        "\n",
        "    # Early stopping check\n",
        "    if wait >= patience:\n",
        "        print(f\"Stopping early at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "# Load in best model\n",
        "if current_val_loss!=best_val_loss:\n",
        "    print(f'Loading model from epoch: {best_epoch}.')\n",
        "    VQA_NET.load_state_dict(torch.load(f'/content/drive/MyDrive/Deep_learning/model_states/new_model_rcnn{best_epoch}.pth'))"
      ],
      "metadata": {
        "id": "c20QE1MvrmLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11001157-580f-42a6-e314-486b96df31d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000] | Training Loss: 7.6554, Validation Loss: 138.0195\n",
            "Accuracy: 0.2543, Precision: 0.1183, Recall: 0.7604, F1 Score: 0.4718\n",
            "Epoch [2/1000] | Training Loss: 3.8346, Validation Loss: 133.8259\n",
            "Accuracy: 0.2709, Precision: 0.1161, Recall: 0.5210, F1 Score: 0.3086\n",
            "Epoch [3/1000] | Training Loss: 3.7429, Validation Loss: 130.4638\n",
            "Accuracy: 0.2769, Precision: 0.1213, Recall: 0.4963, F1 Score: 0.2892\n",
            "Epoch [4/1000] | Training Loss: 3.6720, Validation Loss: 128.9890\n",
            "Accuracy: 0.2769, Precision: 0.1337, Recall: 0.4953, F1 Score: 0.2839\n",
            "Epoch [5/1000] | Training Loss: 3.6112, Validation Loss: 126.8131\n",
            "Accuracy: 0.2799, Precision: 0.1204, Recall: 0.4963, F1 Score: 0.2926\n",
            "Epoch [6/1000] | Training Loss: 3.5374, Validation Loss: 126.0585\n",
            "Accuracy: 0.2799, Precision: 0.2344, Recall: 0.4636, F1 Score: 0.3419\n",
            "Epoch [7/1000] | Training Loss: 3.4810, Validation Loss: 124.3315\n",
            "Accuracy: 0.2799, Precision: 0.1207, Recall: 0.5103, F1 Score: 0.2970\n",
            "Epoch [8/1000] | Training Loss: 3.4419, Validation Loss: 122.5168\n",
            "Accuracy: 0.2863, Precision: 0.1234, Recall: 0.5050, F1 Score: 0.2901\n",
            "Epoch [9/1000] | Training Loss: 3.4047, Validation Loss: 120.3680\n",
            "Accuracy: 0.2713, Precision: 0.1274, Recall: 0.4478, F1 Score: 0.2784\n",
            "Epoch [10/1000] | Training Loss: 3.3708, Validation Loss: 120.4388\n",
            "Accuracy: 0.2919, Precision: 0.1320, Recall: 0.4793, F1 Score: 0.2833\n",
            "Epoch [11/1000] | Training Loss: 3.3327, Validation Loss: 120.0624\n",
            "Accuracy: 0.2908, Precision: 0.1463, Recall: 0.4905, F1 Score: 0.2883\n",
            "Epoch [12/1000] | Training Loss: 3.3047, Validation Loss: 120.1017\n",
            "Accuracy: 0.2867, Precision: 0.2419, Recall: 0.4618, F1 Score: 0.3148\n",
            "Epoch [13/1000] | Training Loss: 3.2816, Validation Loss: 119.8042\n",
            "Accuracy: 0.2825, Precision: 0.1256, Recall: 0.6582, F1 Score: 0.3877\n",
            "Epoch [14/1000] | Training Loss: 3.2551, Validation Loss: 117.8444\n",
            "Accuracy: 0.2874, Precision: 0.1309, Recall: 0.4481, F1 Score: 0.2680\n",
            "Epoch [15/1000] | Training Loss: 3.2334, Validation Loss: 119.6242\n",
            "Accuracy: 0.2893, Precision: 0.1326, Recall: 0.4889, F1 Score: 0.2957\n",
            "Epoch [16/1000] | Training Loss: 3.2146, Validation Loss: 118.6919\n",
            "Accuracy: 0.2750, Precision: 0.1318, Recall: 0.4396, F1 Score: 0.2773\n",
            "Epoch [17/1000] | Training Loss: 3.1911, Validation Loss: 120.5922\n",
            "Accuracy: 0.2923, Precision: 0.1254, Recall: 0.4779, F1 Score: 0.2798\n",
            "Epoch 00018: reducing learning rate of group 0 to 9.8215e-05.\n",
            "Epoch [18/1000] | Training Loss: 3.1640, Validation Loss: 119.2412\n",
            "Accuracy: 0.2878, Precision: 0.1467, Recall: 0.4356, F1 Score: 0.2609\n",
            "Epoch [19/1000] | Training Loss: 3.1476, Validation Loss: 117.7982\n",
            "Accuracy: 0.2938, Precision: 0.2129, Recall: 0.4677, F1 Score: 0.2897\n",
            "Epoch [20/1000] | Training Loss: 3.1321, Validation Loss: 118.1012\n",
            "Accuracy: 0.2878, Precision: 0.1373, Recall: 0.4778, F1 Score: 0.2869\n",
            "Epoch [21/1000] | Training Loss: 3.1155, Validation Loss: 116.6112\n",
            "Accuracy: 0.2931, Precision: 0.2440, Recall: 0.4421, F1 Score: 0.3695\n",
            "Epoch [22/1000] | Training Loss: 3.0982, Validation Loss: 116.7623\n",
            "Accuracy: 0.2957, Precision: 0.1386, Recall: 0.4656, F1 Score: 0.2908\n",
            "Epoch [23/1000] | Training Loss: 3.0786, Validation Loss: 116.4637\n",
            "Accuracy: 0.2916, Precision: 0.1856, Recall: 0.4379, F1 Score: 0.2720\n",
            "Epoch [24/1000] | Training Loss: 3.0606, Validation Loss: 115.7971\n",
            "Accuracy: 0.3014, Precision: 0.2373, Recall: 0.4588, F1 Score: 0.2751\n",
            "Epoch [25/1000] | Training Loss: 3.0348, Validation Loss: 116.3934\n",
            "Accuracy: 0.2878, Precision: 0.2357, Recall: 0.4201, F1 Score: 0.3164\n",
            "Epoch [26/1000] | Training Loss: 3.0288, Validation Loss: 116.2196\n",
            "Accuracy: 0.2961, Precision: 0.2339, Recall: 0.4547, F1 Score: 0.3596\n",
            "Epoch [27/1000] | Training Loss: 3.0081, Validation Loss: 115.9972\n",
            "Accuracy: 0.2942, Precision: 0.1740, Recall: 0.4725, F1 Score: 0.2850\n",
            "Epoch [28/1000] | Training Loss: 2.9913, Validation Loss: 115.7762\n",
            "Accuracy: 0.3040, Precision: 0.2526, Recall: 0.4676, F1 Score: 0.3460\n",
            "Epoch [29/1000] | Training Loss: 2.9695, Validation Loss: 116.5516\n",
            "Accuracy: 0.2976, Precision: 0.2206, Recall: 0.4667, F1 Score: 0.2950\n",
            "Epoch [30/1000] | Training Loss: 2.9734, Validation Loss: 115.6350\n",
            "Accuracy: 0.2953, Precision: 0.2426, Recall: 0.4593, F1 Score: 0.3229\n",
            "Epoch [31/1000] | Training Loss: 2.9538, Validation Loss: 116.2157\n",
            "Accuracy: 0.2927, Precision: 0.1983, Recall: 0.4518, F1 Score: 0.2793\n",
            "Epoch [32/1000] | Training Loss: 2.9506, Validation Loss: 116.3327\n",
            "Accuracy: 0.2953, Precision: 0.1755, Recall: 0.4413, F1 Score: 0.2788\n",
            "Epoch [33/1000] | Training Loss: 2.9189, Validation Loss: 116.3659\n",
            "Accuracy: 0.2968, Precision: 0.1361, Recall: 0.4378, F1 Score: 0.2626\n",
            "Epoch 00034: reducing learning rate of group 0 to 9.6656e-05.\n",
            "Epoch [34/1000] | Training Loss: 2.9051, Validation Loss: 117.1024\n",
            "Accuracy: 0.2878, Precision: 0.2107, Recall: 0.4422, F1 Score: 0.2808\n",
            "Epoch [35/1000] | Training Loss: 2.9053, Validation Loss: 115.7353\n",
            "Accuracy: 0.2931, Precision: 0.2563, Recall: 0.4259, F1 Score: 0.3256\n",
            "Stopping early at epoch 35\n",
            "Loading model from epoch: 30.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9a60d1a36198>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcurrent_val_loss\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mbest_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loading model from epoch: {best_epoch}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mVQA_NET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/Deep_learning/model_states/new_model_baseline{best_epoch}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Deep_learning/model_states/new_model_baseline30.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VQA_NET.load_state_dict(torch.load(f'/content/drive/MyDrive/Deep_learning/model_states/new_model_rcnn30.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bow9tmydtaNX",
        "outputId": "cc1b6bf8-c801-4441-96ba-73fbf986fc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "iDL5ilB6rn_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics for best model"
      ],
      "metadata": {
        "id": "dkzxNWg3rq4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the metrics for the best model\n",
        "accuracy, precision, recall, f1 = calculate_metrics(all_true_labels, all_pred_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "rKxfB2FSrnz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c78b309-0d21-4ad9-d061-d940726d0b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2931, Precision: 0.2563, Recall: 0.4259, F1 Score: 0.3256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation analysis on test data"
      ],
      "metadata": {
        "id": "pSsN4mI2rtld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def categorize_answer(answer):\n",
        "    if answer.lower() in [\"yes\", \"no\"]:\n",
        "        return \"yes/no\"\n",
        "    if answer.isdigit():\n",
        "        return \"numbers\"\n",
        "    return \"others\"\n",
        "\n",
        "# Initialize storage for predictions and labels by category\n",
        "category_metrics = {\n",
        "    \"yes/no\": {\"true_labels\": [], \"predicted_labels\": []},\n",
        "    \"numbers\": {\"true_labels\": [], \"predicted_labels\": []},\n",
        "    \"others\": {\"true_labels\": [], \"predicted_labels\": []},\n",
        "    \"overall\": {\"true_labels\": [], \"predicted_labels\": []}\n",
        "}\n",
        "\n",
        "# Example usage\n",
        "num_samples_to_display = 15\n",
        "samples_displayed = 0\n",
        "\n",
        "test_pred_labels = []\n",
        "test_true_labels = []\n",
        "total_test_loss = 0.0\n",
        "correct_answers = 0\n",
        "total_answers = 0\n",
        "\n",
        "VQA_NET.eval()\n",
        "with torch.no_grad():\n",
        "    for images, questions, labels in test_data_loader:\n",
        "        images, questions, labels = images.to(device), questions.to(device), labels.to(device)\n",
        "        outputs = VQA_NET(images, questions)\n",
        "        loss = CRITERION(outputs, labels)\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_answers += (predicted == labels).sum().item()\n",
        "        total_answers += labels.size(0)\n",
        "        _, predicted_labels = torch.max(outputs, dim=1)\n",
        "        test_pred_labels.extend(predicted_labels.cpu().numpy())\n",
        "        test_true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Categorize answers and store results\n",
        "        for true_label, predicted_label in zip(labels.cpu().numpy(), predicted_labels):\n",
        "            true_answer = label_encoder.inverse_transform([true_label])[0]\n",
        "            predicted_answer = label_encoder.inverse_transform([predicted_label.cpu()])[0]\n",
        "            category = categorize_answer(true_answer)\n",
        "            category_metrics[category][\"true_labels\"].append(true_label)\n",
        "            category_metrics[category][\"predicted_labels\"].append(predicted_label)\n",
        "            category_metrics[\"overall\"][\"true_labels\"].append(true_label)\n",
        "            category_metrics[\"overall\"][\"predicted_labels\"].append(predicted_label)\n",
        "\n",
        "        \"\"\"\n",
        "        for i in range(images.size(0)):\n",
        "            if samples_displayed >= num_samples_to_display:\n",
        "                break\n",
        "\n",
        "            image = tensor_to_image(images[i])\n",
        "            question_text = ' '.join([tokenizer.index_word.get(idx, '?') for idx in questions[i].tolist() if idx != 0])\n",
        "            true_answer_text = label_encoder.inverse_transform([labels[i].item()])[0]\n",
        "            predicted_answer_text = label_encoder.inverse_transform([predicted[i].item()])[0]\n",
        "\n",
        "            \"\"Display the image with the question and predicted answer.\"\"\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Q: {question_text}\\nTrue: {true_answer_text}, Predicted: {predicted_answer_text}\")\n",
        "            plt.show()\n",
        "\n",
        "            samples_displayed += 1\n",
        "\"\"\"\n",
        "\n",
        "# Compute and display metrics for each category\n",
        "for category, data in category_metrics.items():\n",
        "    print(category)\n",
        "    #print(data['true_labels'])\n",
        "    # Convert each tensor in the list to a NumPy array\n",
        "    predicted_labels_cpu = [label.cpu().numpy() for label in data['predicted_labels']]\n",
        "    # Flatten the list of arrays and then apply inverse_transform\n",
        "    #print(label_encoder.inverse_transform(predicted_labels_cpu))\n",
        "\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(data[\"true_labels\"], predicted_labels_cpu)\n",
        "    print(f\"Category: {category} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rx4ZrrXVrnxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ace286-a907-4e48-d23a-f05dc1376c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes/no\n",
            "Category: yes/no - Accuracy: 0.5072, Precision: 0.5373, Recall: 0.5072, F1 Score: 0.4148\n",
            "numbers\n",
            "Category: numbers - Accuracy: 0.2299, Precision: 0.0684, Recall: 0.5220, F1 Score: 0.2178\n",
            "others\n",
            "Category: others - Accuracy: 0.1190, Precision: 0.0447, Recall: 0.3341, F1 Score: 0.1550\n",
            "overall\n",
            "Category: overall - Accuracy: 0.2953, Precision: 0.2426, Recall: 0.4593, F1 Score: 0.3229\n"
          ]
        }
      ]
    }
  ]
}